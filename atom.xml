<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NickChenyx&#39;s Blog</title>
  
  
  <link href="http://nickchenyx.github.io/atom.xml" rel="self"/>
  
  <link href="http://nickchenyx.github.io/"/>
  <updated>2023-09-09T11:00:12.170Z</updated>
  <id>http://nickchenyx.github.io/</id>
  
  <author>
    <name>nickChen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>灯开关补充零线</title>
    <link href="http://nickchenyx.github.io/2023/09/06/%E7%81%AF%E5%BC%80%E5%85%B3%E8%A1%A5%E5%85%85%E9%9B%B6%E7%BA%BF/"/>
    <id>http://nickchenyx.github.io/2023/09/06/%E7%81%AF%E5%BC%80%E5%85%B3%E8%A1%A5%E5%85%85%E9%9B%B6%E7%BA%BF/</id>
    <published>2023-09-06T12:11:31.000Z</published>
    <updated>2023-09-09T11:00:12.170Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本篇文章主要是介绍如何给灯开关上添加零线，至于我为啥要加这个零线，就是非常痛苦的故事了，后面再说。</p><p>先假定你已经明确是需要给灯开关加零线，我直接开始介绍如何操作，最后再补充为什么需要零线的原因。</p><h2 id="灯加零线过程（精简版）"><a href="#灯加零线过程（精简版）" class="headerlink" title="灯加零线过程（精简版）"></a>灯加零线过程（精简版）</h2><ol><li>确认此时灯盒中，只有 L 线（火线）和灯线（也叫负载线），缺少一根零线。</li></ol><blockquote><p>笔者注：此时我的盒子里只有 L线（红色）和灯线（白色），这里的用颜色描述希望可以方便读者快速类比到自己的情况。</p></blockquote><p><img src="/images/light_N/4.jpg" alt="灯上连着 L 线和灯线"></p><ol start="2"><li>找到灯位置的接线，可以看到灯上接入了两根线。</li></ol><blockquote><p>笔者注：此时我的灯上有两根线，一根红线，一根蓝线，按照设计，灯上的红线接火线，蓝线接零线。此时灯红线连着 L线（蓝色），灯蓝线连着零线（白色），灯旁边有一根地线（黄绿色）。</p></blockquote><p><img src="/images/light_N/3.jpg" alt="灯上连着 L 线和灯线"></p><ol start="3"><li>接下来要做的是把灯蓝线接零线（白线）处，分出一根零线，接入到灯盒中。这时候需要到一个、「电工穿线神器」、「电线」和「接线端子压线帽」。</li></ol><blockquote><p>笔者注：这些都是笔者自行淘宝购买的。「电工穿线神器」最好是带滑轮头的，穿墙效果好；「电线」买公牛 BVR 电线 1.5 平方毫米的就行，能满足灯的需求；「接线端子压线帽」是为了连接将灯蓝线、零线（白线）和新穿电线连接在一起，用这个好处是可以将电线压实，防止虚接。当然如果你的电线非常松，能够在灯盒处直接拉动灯线（白色），灯盒处的白线能够从灯处拉出，那就可以直接把新买的「电线」用绝缘胶带多捆几圈绑在灯线（白线）上。这样就不用「电工穿线神器」了，直接利用已有的线带新线。</p></blockquote><blockquote><p>笔者注：笔者家里的线是藏在管道盒子里的，所以需要打开盒子才能穿线</p></blockquote><p><img src="/images/light_N/1.jpg" alt="电线被收在盒子里了，穿线需要把盒子线打开"></p><ol start="5"><li><p>在灯盒处，将新「电线」绑在「电工穿线神器」上（这个可以看「电工穿线神器」的商品说明），然后用「电工穿线神器」从管道口伸入，一点点从灯处穿出。穿出后，将新「电线」和灯蓝线、零线（白色）用「接线端子压线帽」压起来，压好后抽动下几根线，确认压实不会被抽出来。</p></li><li><p>这时候灯盒处已经有了零线了。大功告成！</p></li><li><p>附上修改前后的电路图作为参考<br><img src="/images/light_N/5.jpg" alt="改造前，灯盒处只有两根线"></p></li></ol><p><img src="/images/light_N/6.jpg" alt="改造后，灯盒处有三根线，新接的就是零线"></p><h2 id="为什么灯盒需要零线（躺坑路）"><a href="#为什么灯盒需要零线（躺坑路）" class="headerlink" title="为什么灯盒需要零线（躺坑路）"></a>为什么灯盒需要零线（躺坑路）</h2><p>笔者为了接入智能开关，直接买了零火版的智能开关。我在拆开灯开关盒的时候，发现有两根线，也用电笔测试了下，一个是有电，一个无电，我就以为这是火线和零线了，自然而然地买了零火版的智能开关。在要安装开关的时候，才发现零火版的智能开关，需要连接三根线：</p><ul><li>L线——火线</li><li>N线——零线</li><li>L1线——灯线</li></ul><p>这时候我发现我灯盒里只有两根线！L1线是什么线？这时候才了解到灯盒里原有的红线（火线）和白线（灯线，也就是零火版里的L1线），是没有零线的。这个只有火线和灯线的情况，只能用单火版的智能开关，但是我已经买了零火版的，那我必须要用上啊…… 所以就开始折腾如何在灯盒里接零线了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;本篇文章主要是介绍如何给灯开关上添加零线，至于我为啥要加这个零线，就是非常痛苦的故事了，后面再说。&lt;/p&gt;
&lt;p&gt;先假定你已经明确是需要给灯</summary>
      
    
    
    
    <category term="智能家居" scheme="http://nickchenyx.github.io/categories/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"/>
    
    
    <category term="开关" scheme="http://nickchenyx.github.io/tags/%E5%BC%80%E5%85%B3/"/>
    
    <category term="零线" scheme="http://nickchenyx.github.io/tags/%E9%9B%B6%E7%BA%BF/"/>
    
    <category term="灯" scheme="http://nickchenyx.github.io/tags/%E7%81%AF/"/>
    
  </entry>
  
  <entry>
    <title>curl 实战</title>
    <link href="http://nickchenyx.github.io/2022/10/14/curl_usage/"/>
    <id>http://nickchenyx.github.io/2022/10/14/curl_usage/</id>
    <published>2022-10-14T14:19:41.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h3 id="耗时分析"><a href="#耗时分析" class="headerlink" title="耗时分析"></a>耗时分析</h3><pre><code class="shell">$ man curl  # 查看 curl 的使用方式-w, --write-out &lt;format&gt; # -w 参数配置输出格式</code></pre><p><code>-w</code> 参数中有部分时间相关的参数如下：</p><ul><li><code>time_namelookup</code>：从请求开始到 DNS 域名解析完成的耗时</li><li><code>time_connect</code>：从请求开始到 TCP 连接建立耗时(三次握手)</li><li><code>time_appconnect</code>：从请求开始到 SSL/SSH 等建立连接耗时( ssl handshake 等)</li><li><code>time_pretransfer</code>：从请求开始到响应开始传输的时间</li><li><code>time_redirect</code>：从请求开始到，包含前面四者耗时，且所有重定向的时间相加，直到最终访问目标服务前的耗时</li><li><code>time_starttransfer</code>：从请求开始到第一个字节将要传输的耗时，包含了 <code>time_pretransfer</code> 耗时</li><li><code>time_total</code>：请求的全部耗时</li></ul><p><strong>如何发起耗时分析请求</strong></p><ol><li>直接在命令行中拼写输出格式<pre><code class="shell">curl -w &#39;\ntime_namelookup=%&#123;time_namelookup&#125;\ntime_connect=%&#123;time_connect&#125;\ntime_appconnect=%&#123;time_appconnect&#125;\ntime_redirect=%&#123;time_redirect&#125;\ntime_pretransfer=%&#123;time_pretransfer&#125;\ntime_starttransfer=%&#123;time_starttransfer&#125;\ntime_total=%&#123;time_total&#125;\n\n&#39; -o /dev/null -s -L &#39;http://voidchen.com&#39;</code></pre></li></ol><ol start="2"><li>利用文件描述格式<br>创建一个格式文件 <code>format.txt</code><pre><code> time_namelookup:  %&#123;time_namelookup&#125;\n    time_connect:  %&#123;time_connect&#125;\n time_appconnect:  %&#123;time_appconnect&#125;\n   time_redirect:  %&#123;time_redirect&#125;\ntime_pretransfer:  %&#123;time_pretransfer&#125;\ntime_starttransfer:  %&#123;time_starttransfer&#125;\n                 ----------\n      time_total:  %&#123;time_total&#125;\n</code></pre>使用格式文件发起访问<pre><code class="shell">curl -w &#39;@format.txt&#39; -o /dev/null -s -L &#39;http://voidchen.com&#39;</code></pre></li></ol><p><strong>耗时计算</strong></p><ol><li>DNS耗时 = time_namelookup</li><li>TCP建连耗时 = time_connect - time_namelookup</li><li>SSL握手耗时 = time_appconnect - time_connect</li><li>服务器处理请求耗时 = time_starttransfer - time_pretransfer</li><li>TTFB耗时 = time_starttransfer - time_appconnect</li><li>服务器传输耗时 = time_total - time_starttransfer</li><li>总耗时 = time_total</li></ol><blockquote><p>TODO 分析脚本</p></blockquote><p><strong>参考</strong></p><ul><li><a href="https://www.nixops.me/articles/curl-http-timing.html">通过 curl 命令分析 http 性能</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;耗时分析&quot;&gt;&lt;a href=&quot;#耗时分析&quot; class=&quot;headerlink&quot; title=&quot;耗时分析&quot;&gt;&lt;/a&gt;耗时分析&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;shell&quot;&gt;$ man curl  # 查看 curl 的使用方式

-w, --write</summary>
      
    
    
    
    <category term="Linux" scheme="http://nickchenyx.github.io/categories/Linux/"/>
    
    
    <category term="curl" scheme="http://nickchenyx.github.io/tags/curl/"/>
    
  </entry>
  
  <entry>
    <title>Linux 查看进程启动命令和环境变量</title>
    <link href="http://nickchenyx.github.io/2022/10/14/linux_show_proc_cmdline/"/>
    <id>http://nickchenyx.github.io/2022/10/14/linux_show_proc_cmdline/</id>
    <published>2022-10-14T14:11:43.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<ol><li>查询目标进程，通过 ps -ef | grep {target process name} 查询进程 pid（ps -aux 也行）</li><li><code>cat /proc/&#123;pid&#125;/cmdline</code> 可以查询到进程的启动参数，但是现在的格式不大好读，可以用下面的命令优化下输出</li><li><code>cat /proc/&#123;pid&#125;/cmdline | tr &quot;\0&quot; &quot;\n&quot;</code>  用空格分割各个运行时参数，方便阅读</li><li><code>cat /proc/&#123;pid&#125;/environ | tr &quot;\0&quot; &quot;\n</code> 可以查询到进程运行时的环境变量</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;查询目标进程，通过 ps -ef | grep {target process name} 查询进程 pid（ps -aux 也行）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cat /proc/&amp;#123;pid&amp;#125;/cmdline&lt;/code&gt; 可以查询到进程的</summary>
      
    
    
    
    <category term="Linux" scheme="http://nickchenyx.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="http://nickchenyx.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>认识 Scrum 和产品开发流程</title>
    <link href="http://nickchenyx.github.io/2022/07/24/scrum/"/>
    <id>http://nickchenyx.github.io/2022/07/24/scrum/</id>
    <published>2022-07-24T08:00:06.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是-Scrum"><a href="#什么是-Scrum" class="headerlink" title="什么是 Scrum"></a>什么是 Scrum</h2><blockquote><p><a href="https://www.scrum.org/resources/what-is-scrum">WHAT IS SCRUM</a></p></blockquote><p>简而言之，Scrum 需要一个管理者营造出这样一种环境：</p><ol><li>一个产品负责人将复杂问题排序放入一个任务队列中</li><li>Scrum 团队在一个 Sprint 周期内选出一部分工作完成，实现价值增长</li><li>Scrum 团队和利益相关者检查这个 Sprint 周期的产出结果，并为下个 Sprint 进行调整</li><li>重复执行以上动作</li></ol><h2 id="Scrum-术语词汇表"><a href="#Scrum-术语词汇表" class="headerlink" title="Scrum 术语词汇表"></a>Scrum 术语词汇表</h2><blockquote><p><a href="https://www.scrum.org/resources/scrum-glossary">Scrum Glossary</a></p></blockquote><table><thead><tr><th>专业名词</th><th>名词解释</th></tr></thead><tbody><tr><td>Burn-Down Chart</td><td>燃尽图，用于表示产品任务队列的剩余任务数量</td></tr><tr><td>Burn-Up Chart</td><td>燃烧图，用于表示已完成的任务数量</td></tr><tr><td>Daily Scrum</td><td>每日Scrum汇报，大约十五分钟，在一个 Sprint 周期的每天都需要执行。Developer 会确认未来二十四小时的开发计划。在这个过程中，会检查上个 Daily Scrum 的结果，并调整这个 Sprint 接下来的工作。这有助于提高团队人员之间的协作和效率。Daily Scrum 可以很好的减少 Sprint 的复杂度</td></tr><tr><td>Definition of Done</td><td>产品任务完成的定义。任务队列中任务在执行时需要有明确的完成定义，这可以让团队对任务有更清晰的共同理解。如果一个产品任务不符合 Definition of Done，它就不可以被发布，也不能在 Sprint Review 中展示</td></tr><tr><td>Developer</td><td>隶属于 Scrum 团队的任何一名成员。</td></tr><tr><td>Increment</td><td>在 Sprint 期间产生的所有完整且有价值的工作就是 Scrum 的产出。所有的这些增量（Increment）的组合，就构成了一个产品</td></tr><tr><td>Product Backlog</td><td>产品任务队列。Scrum 的产物由一个有序的任务清单组成，这个清单可以创造、维护、和维持一个产品。Product Backlog 由产品负责人（Product Owner）管理</td></tr><tr><td>Product Owner</td><td>负责将产品的价值最大化，主要是通过逐步管理并向开发人员表达对产品的业务和功能期望</td></tr><tr><td>Product Goal</td><td>产品目标描述了产品的未来状态，可以作为 Scrum 团队计划的一个目标。Product Goal 在 Product Backlog 中，Product Backlog 剩余的任务定义了如何来实现 Product Goal</td></tr><tr><td>Ready</td><td>产品负责人（Product Owner）和开发人员（Developer）对在 Sprint 中引入的任务有共同的理解</td></tr><tr><td>Scrum Board</td><td>一个实体面板，用于为 Scrum 团队提供可视化的信息，通常用于管理 Sprint Backlog</td></tr><tr><td>Scrum Master</td><td>在 Scrum 团队中负责指导、辅导、教导和协助 Scrum 团队，确保对 Scrum 的正确理解和使用</td></tr><tr><td>Sprint</td><td>在 Scrum 中的一个重要组成事件，时间通常为一个月或者更短，作为其他 Scrum 事件和活动的一个容器。Sprint 是连续运行的，没有空隙</td></tr><tr><td>Sprint Backlog</td><td>在一个 Sprint 期间需要执行的任务清单，指明了这个 Sprint 周期内的产品目标</td></tr><tr><td>Sprint Goal</td><td>对 Sprint 周期内需要完成的目标的简短描述</td></tr><tr><td>Sprint Planning</td><td>一个 Scrum 事件，以八小时或者更短的时间来开始一个 Sprint。它的作用是让 Scrum 团队检查产品任务清单（Product Backlog）中，接下来最有价值的工作，并将这些工作设计到下个 Sprint 任务清单（Sprint Backlog）中</td></tr><tr><td>Sprint Retrospective</td><td>一个 Scrum 事件，以三个小时或更短的时间来结束一个 Sprint。它的作用是让 Scrum 团队检查刚过去的 Sprint，并计划在未来的 Sprint 中进行改进</td></tr><tr><td>Sprint Review</td><td>一个 Scrum 事件，以四小时或者更短的时间来总结刚过去的 Sprint 中的开发工作。它的作用是让 Scrum 团队和利益相关者检查 Sprint 的产出，评估所做的工作对实现产品目标的总体进展的影响，并更新产品任务清单，以使下个阶段的价值最大化</td></tr><tr><td>Stakeholder</td><td>利益相关者，Scrum 团队的外部成员，会在 Sprint Review 中与 Scrum 团队进行积极互动，关心 Sprint 的增量产出（Increment）</td></tr><tr><td>Technical Debt</td><td>技术债务</td></tr><tr><td>Velocity</td><td>一个可选的，但是经常使用的指标，表明 Scrum 团队在 Sprint 期间将产品任务清单（Product Backlog）转化为产品增量（Increment）的数量，由开发人员跟踪，供 Scrum 团队使用</td></tr></tbody></table><p>另外，当软件开发团队使用 Scrum 和敏捷编程时，也有些专业词汇。参考 <a href="https://www.scrum.org/resources/professional-scrum-developer-glossary">Professional Scrum Developer Glossary</a> </p><table><thead><tr><th>专业名词</th><th>名词解释</th></tr></thead><tbody><tr><td>User Story</td><td>来自极限编程的敏捷软件开发实践，从终端用户的角度表达需求，强调口头交流。在 Scrum 中，它经常被用来表达产品任务清单（Product Backlog）上的一组任务</td></tr></tbody></table><h2 id="Scrum-工作流"><a href="#Scrum-工作流" class="headerlink" title="Scrum 工作流"></a>Scrum 工作流</h2><p>图片来源：<a href="https://www.scrum.org/resources/what-is-scrum">https://www.scrum.org/resources/what-is-scrum</a><br><img src="/images/scrum/scrumorg-scrum-framework-3000.png" alt="scrumorg-scrum-framework-3000"></p><p>本图描述了一个完整的 Scrum 工作流，其中的各个单元都在上文的名词解释中有提及。<br>图中的每个节点就是项目过程中我们需要关注的指标，节点之间流转就是管理人员需要介入的时间点。</p><p>从节点和流转的视角来看：</p><table><thead><tr><th>节点</th><th>节点指标</th><th>流入</th><th>流出</th></tr></thead><tbody><tr><td>产品任务队列（Product Backlog）</td><td>待开发任务的总和，需要关注燃尽&amp;燃烧的情况</td><td>需要产品&amp;项目负责人把关流入的需求</td><td>流出是转入下一个开发周期（Sprint）需要确认下个周期的排期安排</td></tr><tr><td>周期开发计划（Sprint Planning）</td><td>关注会议的时间和结论，需要控制好时间和验证结论的合理性</td><td>需要确认优先级高的需求优先进入开发周期，但是需要关心需求的连贯性和整体性，我们的目标是本开发周期（Sprint）后的的产品增量（increment）能产生更大价值</td><td>需要将最终决定的需求整理好进入开发周期任务队列 （Sprint Backlog）</td></tr><tr><td>开发周期任务队列（Sprint Backlog）</td><td>进入到开发周期了，在这里依然要关注燃尽的情况，更重要的是需要对产品增量（Increament）负责，要将本开发周期的目标向最终产物对齐的同时，保障开发任务能按时交付</td><td>必须是整合过后的优先级高的需求流入，进入此队列时，需要对其开发资源，确保交付周期和质量</td><td>进入开发周期日会，检验成果</td></tr><tr><td>每日 Scrum 汇报（Daily Scrum）</td><td>这是开发周期（Sprint）内的必要动作，日报需要关注昨天的开发情况，提早发现问题&amp;暴露风险，也要规划今天的开发任务。这里并不是说在当天才确认当天的开发任务，而是对原定开发任务的一个补充。是根据之前的 Daily Scrum 已知问题和暴露风险，重新协调团队资源解决。这也是软件开发工作必须具备的提前量。</td><td>需要关心昨天开发工作中遇到的问题，也包含产品上可能的突发变动，或者是目标微调。这些问题需要在当日的 Daily Scrum 上提出</td><td>根据已知的问题和风险，重新协调团队资源解决问题，对当天的开发计划重新对齐</td></tr><tr><td>产品增量（Increment）</td><td>关注产品功能和质量</td><td>一个开发周期（Sprint）的最终产物</td><td>验收确认可交付的产物</td></tr><tr><td>开发回顾（Sprint Review）</td><td>评估产出的质量，找出上个周期开发不足，在下个周期时予以改正。评估本周期的工作对实现产品目标的总体进展的影响，并更新产品任务队列（Product Backlog），使下个阶段的开发价值最大化</td><td>上个开发周期（Sprint）的各种信息</td><td>找到团队问题和解法；评估产品目标进展和更新任务产品队列（Product Backlog）</td></tr><tr><td>开发回顾（Sprint Retrospective）</td><td>这个节点和 Sprint Review 类似，如果细分开的话可以将上一个节点视为产品价值的 review，这个节点更偏向于团队工作的 review</td><td>-</td><td>-</td></tr></tbody></table><h2 id="Scrum-实践"><a href="#Scrum-实践" class="headerlink" title="Scrum 实践"></a>Scrum 实践</h2><p><strong>理论是如何被实践的？实践过程中会遇到什么问题？解决的方案是否结合了理论？</strong></p><ol><li>各个节点和流转的负责人是谁？有什么工具可以支撑？</li><li>实际工作中，涉及需求理解的多方对齐，有无流程上的保障？（角色需求复述）</li><li>实际开发过程中，一个 WEB/APP/OTHER 项目开发会有什么特别流程？(产品试用)</li><li>如何做产品价值的 Review？（AB、数据分析）</li><li>实际工作中会有多种角色，并且角色介入产品开发的时间各不相同，如何串联起各角色的时间？（各个时间线的排期，各团队的 leader 先一步确认需求和大致排期）</li></ol><p>#TODO </p><p>从《实例化需求：团队如何交付正确的软件》寻找部分解法</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是-Scrum&quot;&gt;&lt;a href=&quot;#什么是-Scrum&quot; class=&quot;headerlink&quot; title=&quot;什么是 Scrum&quot;&gt;&lt;/a&gt;什么是 Scrum&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.scrum.or</summary>
      
    
    
    
    <category term="管理" scheme="http://nickchenyx.github.io/categories/%E7%AE%A1%E7%90%86/"/>
    
    
    <category term="scrum" scheme="http://nickchenyx.github.io/tags/scrum/"/>
    
  </entry>
  
  <entry>
    <title>漫谈 Golang 之 map</title>
    <link href="http://nickchenyx.github.io/2022/07/23/golang-map-dive-into/"/>
    <id>http://nickchenyx.github.io/2022/07/23/golang-map-dive-into/</id>
    <published>2022-07-23T12:59:01.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h3 id="map-参数传递"><a href="#map-参数传递" class="headerlink" title="map 参数传递"></a>map 参数传递</h3><p>当 map 作为参数被传递时，实际上传递的 map 的指针信息，传递后的修改会同步到函数外。</p><p>可以看到 m 被传递到了 <code>onMap</code> 函数中，但是最后在函数外的 m 也是被修改了的。</p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    m := map[int]int&#123;&#125;    opMap(m)    printMap(m)&#125;func opMap(m map[int]int) &#123;    for i := 0; i &lt; 10; i++ &#123;        m[i] = i        printMap(m)    &#125;&#125;func printMap(m map[int]int) &#123;    fmt.Printf(&quot;len: %v, map: %v\n&quot;, len(m), m)&#125;// Output:// len: 1, map: map[0:0]// len: 2, map: map[0:0 1:1]// len: 3, map: map[0:0 1:1 2:2]// len: 4, map: map[0:0 1:1 2:2 3:3]// len: 5, map: map[0:0 1:1 2:2 3:3 4:4]// len: 6, map: map[0:0 1:1 2:2 3:3 4:4 5:5]// len: 7, map: map[0:0 1:1 2:2 3:3 4:4 5:5 6:6]// len: 8, map: map[0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:7]// len: 9, map: map[0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:7 8:8]// len: 10, map: map[0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:7 8:8 9:9]// len: 10, map: map[0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:7 8:8 9:9]</code></pre><h3 id="无法对-map-value-取地址"><a href="#无法对-map-value-取地址" class="headerlink" title="无法对 map value 取地址"></a>无法对 map value 取地址</h3><p>如下的代码中，尝试获取 map value 的地址，会在编译时显示失败。</p><p><a href="https://stackoverflow.com/questions/32495402/why-does-go-forbid-taking-the-address-of-map-member-yet-allows-slice-el">Why Go forbid taking the address of map member</a></p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    m := map[int]int&#123;&#125;    address := &amp;m[0] // invalid operation: cannot take address of m[0] (map index expression of type int)    fmt.Println(address)&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;map-参数传递&quot;&gt;&lt;a href=&quot;#map-参数传递&quot; class=&quot;headerlink&quot; title=&quot;map 参数传递&quot;&gt;&lt;/a&gt;map 参数传递&lt;/h3&gt;&lt;p&gt;当 map 作为参数被传递时，实际上传递的 map 的指针信息，传递后的修改会同步到函数外。</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>漫谈 Golang 之 slice</title>
    <link href="http://nickchenyx.github.io/2022/07/19/golang-slice-dive-into/"/>
    <id>http://nickchenyx.github.io/2022/07/19/golang-slice-dive-into/</id>
    <published>2022-07-19T14:39:40.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Part1: array &amp; slice</strong></p><pre><code class="go">// define a slices := make([]int, 10)// define an arraya := [10]int&#123;&#125;</code></pre><ul><li>定义 slice 第一种方式<pre><code class="go">var s []int</code></pre></li><li>定义 slice 第二种方式<pre><code class="go">s := make([]int, len, cap)</code></pre></li><li>array <pre><code class="go">var a [length]type// var a [10]int</code></pre></li></ul><p><strong>Part2: 类型</strong></p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    var a [8]int    printArray(a)&#125;func printArray(a [10]int) &#123;    fmt.Println(len(a))    fmt.Println(cap(a))&#125;</code></pre><p>以上代码中，<code>printArray(a)</code> 是否可以正常执行？答案是否定的，编译期就会提示错误</p><pre><code>cannot use a (type [8]int) as type [10]int in argument to printArray</code></pre><p>可以看到提示中变量 <code>a</code> 的类型是 <code>type [8]int</code>，而函数 <code>printArray</code> 要求的入参类型是 <code>type [10]int</code>。可见 array 的长度也是其类型的一部分！</p><p><strong>Part3: slice grow</strong></p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    var s []int    for i := 0; i &lt; 1025; i++ &#123;        s = append(s, i)    &#125;    fmt.Println(len(s)) // 1025    fmt.Println(cap(s)) // 1280 = 1024*1.25&#125;</code></pre><p>slice 扩容的方式是：<a href="https://github.com/golang/go/blob/go1.17/src/runtime/slice.go#L162">source code</a></p><ul><li>cap &lt; 1024 –&gt; cap * 2</li><li>cap &gt; 1024 –&gt; cap * 1.25</li></ul><p><code>append</code> 多个参数的对于 <code>slice</code> 容量的影响是不同的，特殊case：</p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    var s1, s2, s3, s4, s5 []int    s1 = append(s1, 0) // len 1, cap 1    printSlice(s1)    s2 = append(s2, 0, 1) // len 2, cap 2    printSlice(s2)    s3 = append(s3, 0, 1, 2) // len 3, cap 3    printSlice(s3)    s4 = append(s4, 0, 1, 2, 3) // len 4, cap 4    printSlice(s4)    s5 = append(s5, 0, 1, 2, 3, 4) // len 5, cap 6    printSlice(s5)&#125;func printSlice(s []int) &#123;    fmt.Println(len(s))    fmt.Println(cap(s))&#125;</code></pre><p><strong>Part4: slice append</strong><br>如何快速完成一次 <code>slice</code> 数据填充？</p><ol><li>声明一个 <code>slice</code> 直接开始 <code>append</code></li><li>声明固定长度 <code>slice</code> 后开始 <code>append</code></li><li>声明固定长度 <code>slice</code> 后，使用 <code>index</code> 进行数据填充</li></ol><p>可以看到方法三是最快的。</p><p>对于大数组的赋值，常用的优化方式还有一种 BCE，可以参考这篇文章中的用法，不再赘述。<a href="https://go101.org/article/bounds-check-elimination.html">golang 边界检查优化</a></p><pre><code class="go">package mainimport &quot;testing&quot;func BenchmarkAppend(b *testing.B) &#123;    var s []int    for i := 0; i &lt; b.N; i++ &#123;        s = append(s, i)    &#125;&#125;func BenchmarkMakeSliceAppend(b *testing.B) &#123;    s := make([]int, 0, b.N)    for i := 0; i &lt; b.N; i++ &#123;        s = append(s, i)    &#125;&#125;func BenchmarkIndex(b *testing.B) &#123;    s := make([]int, b.N)    for i := 0; i &lt; b.N; i++ &#123;        s[i] = i    &#125;&#125;// Output// goos: darwin// goarch: amd64// cpu: Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz// BenchmarkAppend-8                457261122            14.93 ns/op// BenchmarkMakeSliceAppend-8       1000000000             1.407 ns/op// BenchmarkIndex-8                 1000000000             1.246 ns/op</code></pre><p><strong>Part5: slice 扩容带来的”意外”</strong></p><p>当使用 index 修改 slice 时，可能会出现”时而生效时而不生效的情况”，究其原因是 slice 在 grow 的过程中重新分配了内存地址。</p><p>下面这个情况展示接收 slice 的函数 <code>sliceAppend</code> 修改了 index 但是在函数外不生效的情况。</p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    var s []int    s = append(s, 1)    printSlice(s)    sliceAppend(s)    printSlice(s)&#125;func sliceAppend(s []int) &#123;    s = append(s, 1) // 此处发生了扩容操作，导致 s 的内存地址改变    s[0] = 0    printSlice(s)&#125;func printSlice(s []int) &#123;    fmt.Printf(&quot;len: %v, cap: %v, val: %v\n&quot;, len(s), cap(s), s)&#125;// Output:// len: 1, cap: 1, val: [1]// len: 2, cap: 2, val: [0 1]// len: 1, cap: 1, val: [1]</code></pre><p>其实，扩容的发生导致函数内外的可见性也不一样了。和上个例子差不多的一个案例。<br>可以看到，此处两个 slice s 打印出来，结果是不一样的。看起来就是函数内的 s 比函数外的 s 数据更多了！换句话说，在实际场景中，很有可能因为如下这样的误操作，导致看似操作过 s，但是数据缺丢失了。</p><pre><code class="go">package mainimport &quot;fmt&quot;func main() &#123;    var s []int    s = append(s, 1)    printSlice(s)    sliceAppend(s)    printSlice(s)&#125;func sliceAppend(s []int) &#123;    s = append(s, 1) // 此处发生了扩容操作，导致 s 的内存地址改变    printSlice(s)&#125;func printSlice(s []int) &#123;    fmt.Printf(&quot;len: %v, cap: %v, val: %v\n&quot;, len(s), cap(s), s)&#125;// Output:// len: 1, cap: 1, val: [1]// len: 2, cap: 2, val: [1 1]// len: 1, cap: 1, val: [1]</code></pre><p><strong>！！如果发生了扩容，修改会在新的内存中！！</strong></p><p>所以针对 slice 的操作，务必使用 append 函数返回的 slice 对象进行后续操作，避免出现奇怪的数据异常！</p><p><strong>Part6: slice 序列化</strong></p><p>如下案例所示，slice 的 zero value 经过默认的 json 库序列化结果是 <code>null</code>，但是初始化的 slice 经过默认的 json 库序列化结果就是 <code>[]</code>。</p><pre><code class="go">package mainimport (    &quot;encoding/json&quot;    &quot;fmt&quot;)func main() &#123;    var s []int    b, _ := json.Marshal(s)    fmt.Println(string(b))&#125;// Output:// null</code></pre><pre><code class="go">package mainimport (    &quot;encoding/json&quot;    &quot;fmt&quot;)func main() &#123;    s := []int&#123;&#125;    b, _ := json.Marshal(s)    fmt.Println(string(b))&#125;// Output:// []</code></pre><pre><code class="go">package mainimport (    &quot;encoding/json&quot;    &quot;fmt&quot;)func main() &#123;    s := make([]int, 0, 1)    b, _ := json.Marshal(s)    fmt.Println(string(b))&#125;// Output:// []</code></pre><pre><code class="go">package mainimport (    &quot;encoding/json&quot;    &quot;fmt&quot;)func main() &#123;    s := make([]int, 1)    b, _ := json.Marshal(s)    fmt.Println(string(b))&#125;// Output:// [0]</code></pre><blockquote><p>TODO 如果有更多再补充</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Part1: array &amp;amp; slice&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;go&quot;&gt;// define a slice
s := make([]int, 10)
// define an array
a := [10]in</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>漫谈 Golang 空指针 panic 场景</title>
    <link href="http://nickchenyx.github.io/2022/07/07/golang_nil_pointer_panic/"/>
    <id>http://nickchenyx.github.io/2022/07/07/golang_nil_pointer_panic/</id>
    <published>2022-07-07T14:23:14.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要用于分析几类 Golang 空指针引起的 panic 场景，这些场景遍布在日常开发代码中。但是出现 panic 时，真的能根据空指针信息准确定位出原因，找出故障代码吗？</p><p><strong>来看看熟悉的 panic 信息</strong></p><pre><code>panic: runtime error: invalid memory address or nil pointer dereference</code></pre><h2 id="见识一下“熟悉”的-panic"><a href="#见识一下“熟悉”的-panic" class="headerlink" title="见识一下“熟悉”的 panic"></a>见识一下“熟悉”的 panic</h2><h3 id="空-map-赋值"><a href="#空-map-赋值" class="headerlink" title="空 map 赋值"></a>空 map 赋值</h3><p><strong>source code</strong></p><pre><code class="go">package mainfunc main() &#123;    var m map[int]int m[1] = 1&#125;// Output:// panic: assignment to entry in nil map</code></pre><p>第一个需要避免的就是对未初始化的 map 进行赋值，当然，这个并不是本篇文章需要讨论的，但是笔者认为 map 作为常用的组件，还是需要在编码时避免此场景发生。</p><h3 id="结构体指针未初始化"><a href="#结构体指针未初始化" class="headerlink" title="结构体指针未初始化"></a>结构体指针未初始化</h3><p>可以看出 <code>t.n</code> 结构体会跟随者 <code>T</code> 的初始化而完成初始化，此时 <code>t.n.Log0()</code> 和<code>t.n.Log()</code> 调用都成功了。<br>但是 <code>t.np</code> 结构体指针并不会随着 <code>T</code> 的初始化而完成初始化，此时 <code>t.np</code> 实际类型是 <code>(*N)nil</code> ，它是有类型的，类型为 <code>*N</code>，但是 <code>t.np</code> 值为 nil。因此 <code>t.np.Log()</code> 能正常调用，但是 <code>t.np.Log0()</code> 则会 <code>panic</code>。</p><p><strong>source code</strong></p><pre><code class="go">package mainimport (    &quot;fmt&quot;)type T struct &#123;    n  N    np *N&#125;type N struct &#123;    n int&#125;func (n N) Log0() &#123;    fmt.Println(&quot;n log0&quot;)&#125;func (n *N) Log() &#123;    fmt.Println(&quot;n log&quot;)&#125;func main() &#123;    t := T&#123;&#125;    t.n.Log()    t.n.Log0()    t.np.Log()    t.np.Log0()&#125;// Output:// n log// n log0// n log// panic: runtime error: invalid memory address or nil pointer dereference</code></pre><h3 id="interface-未初始化"><a href="#interface-未初始化" class="headerlink" title="interface{} 未初始化"></a>interface{} 未初始化</h3><p>相较于结构体指针，当成员变量是一个接口(<code>interface&#123;&#125;</code>)时，结果又会变得不一样。</p><p>此时 <code>t.m</code> 是一个接口 <code>M</code>，当初始化创建 <code>T</code> 时，如果不主动初始化 <code>M</code> ，那么此时 <code>M</code> 是一个 <code>nil</code>。调用 <code>t.m.Log()</code> 会造成 <code>panic</code>。</p><p><strong>source code 1</strong></p><pre><code class="go">package mainimport (    &quot;fmt&quot;)type T struct &#123;    m M&#125;type M interface &#123;    Log()&#125;type M1 struct &#123;&#125;func (m *M1) Log() &#123;    fmt.Println(&quot;m1 log&quot;)&#125;func main() &#123;    t := T&#123;        m: &amp;M1&#123;&#125;,    &#125;    t.m.Log()    t = T&#123;&#125;    t.m.Log()&#125;// Output:// m1 log// panic: runtime error: invalid memory address or nil pointer dereference</code></pre><p><strong>source code 2</strong></p><pre><code class="go">package maintype M interface &#123;    Log()&#125;func main() &#123;    var m M    m.Log()&#125;// Output:// panic: runtime error: invalid memory address or nil pointer dereference</code></pre><h3 id="interface-assign-nil"><a href="#interface-assign-nil" class="headerlink" title="interface{} assign nil"></a>interface{} assign nil</h3><p>这个 case 在代码中常有发生，根因还是在于 Golang 的 nil 机制有个特殊的地方，可以看<strong>source code 1</strong>。</p><p><strong>source code 1</strong></p><pre><code class="go">package mainimport (    &quot;fmt&quot;)func main() &#123;    var i interface&#123;&#125;    var n *int32    if n == nil &#123;        fmt.Println(&quot;n is nil&quot;)    &#125;    if i == nil &#123;        fmt.Println(&quot;i is nil&quot;)    &#125;    i = n    if i != nil &#123;        fmt.Println(&quot;after assign, i is not nil&quot;)    &#125;&#125;// Output:// n is nil// i is nil// after assign, i is not nil</code></pre><p>基于这个规则，常见的业务中出现 <code>panic</code> 的场景可以看如下代码。在这个场景下，<code>panic</code> 的原因同<strong>结构体指针未初始化</strong>的场景一致，根因是对于变量是否为 nil 的判断上出了问题。</p><p><strong>source code 2</strong></p><pre><code class="go">package mainimport (    &quot;fmt&quot;)type M interface &#123;    Log()&#125;type M1 struct &#123;&#125;func (m M1) Log0() &#123;    fmt.Println(&quot;log0&quot;)&#125;func (m *M1) Log() &#123;    fmt.Println(&quot;log&quot;)&#125;func main() &#123;    var i interface&#123;&#125;    var m M    var s *M1    if i == nil &#123;        fmt.Println(&quot;i is nil&quot;)    &#125;    i = m    if i == nil &#123;        fmt.Println(&quot;after assign m, i is nil&quot;)    &#125;    i = s    if i != nil &#123;        fmt.Println(&quot;after assign s, i is not nil&quot;)    &#125;    // 业务中常用 == nil 判断，然后快速失败 return    if i == nil &#123;        return    &#125;    // 业务中会认为此时的 i 就是非 nil 的了，然后开始进行方法调用    // 和结构体指针未初始化的场景一样，这里调用 *M 的方法是可以进行的    i.(*M1).Log()    // 但是如果调用的是 M 的方法，那就出问题了，panic 随之而来    i.(*M1).Log0()&#125;// Output:// i is nil// after assign m, i is nil// after assign s, i is not nil// log// panic: runtime error: invalid memory address or nil pointer dereference</code></pre><p>要改变是否为 nil 的判断，确保这种 case 不会发生。可以使用：</p><pre><code class="go">func IsNil(x interface&#123;&#125;) &#123;    return x == nil || (reflect.ValueOf(x).Kind() == reflect.Ptr &amp;&amp; reflect.ValueOf(x).IsNil())&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文主要用于分析几类 Golang 空指针引起的 panic 场景，这些场景遍布在日常开发代码中。但是出现 panic 时，真的能根据空指针信息准确定位出原因，找出故障代码吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;来看看熟悉的 panic 信息&lt;/strong&gt;&lt;/p&gt;
&lt;pre</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>Golang 开源之 retry-go 使用指南</title>
    <link href="http://nickchenyx.github.io/2022/06/12/golang-retry-usage/"/>
    <id>http://nickchenyx.github.io/2022/06/12/golang-retry-usage/</id>
    <published>2022-06-12T10:59:22.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/avast/retry-go">retry-go</a> 实现非常优美的 retry 库<br>2022/06/15 仿写实现同样的功能 <a href="https://github.com/nickChenyx/retry-go-dummy">https://github.com/nickChenyx/retry-go-dummy</a></p></blockquote><h2 id="功能测试"><a href="#功能测试" class="headerlink" title="功能测试"></a>功能测试</h2><ol><li>定义了两种错误 <code>SomeErr&amp; AnotherErr</code> ，用来测试 <code>retry-go</code> 库的不同函数</li><li>测试一个常见的 HTPP GET 场景</li><li><code>retry.Do(func() error, ...opt)</code> 使用 <code>Do</code> 函数立马开始进行 retry 操作，简单的使用一个 <code>func() error</code> 包括将要被 retry 的代码</li><li>多种 opt 之 <code>retry.DelayType(func(n uint, err error, config *retry.Config) time.Duration)</code> 主要能力是提供每次重试延迟的时间</li><li>多种 opt 之 <code>retry.OnRetry(func(n uint, err error)</code> 主要能力是再触发 retry 操作的时候，前置执行该函数，可用于日志记录等</li><li>多种 opt 之 <code>retry.RetryIf(func(err error) bool</code> 主要能力是判断是否要触发 retry，可以根据不同的错误类型选择是否要进行 retry 操作</li><li>多种 opt 之 <code>retry.Attempts(uint)</code> 主要是设置重试次数，限制重试的时间</li><li>额外功能之 <code>retry.BackOffDelay(n, err, config)</code> 使用在 <code>retry.DelayType(...)</code> 中，可以设置指数级增长的 delay 时间</li></ol><pre><code class="golang">type SomeErr struct &#123;    err        string    retryAfter time.Duration&#125;func (err SomeErr) Error() string &#123;    return err.err&#125;type AnotherErr struct &#123;    err string&#125;func (err AnotherErr) Error() string &#123;    return err.err&#125;func TestHttpGet(t *testing.T) &#123;    ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123;        fmt.Fprintln(w, &quot;hello&quot;)    &#125;))    defer ts.Close()    var body []byte    var retrySum uint    err := retry.Do(        func() error &#123;            resp, err := http.Get(ts.URL)            ri := rand.Intn(10)            if ri &lt; 3 &#123;                err = SomeErr&#123;                    err:        &quot;some err&quot;,                    retryAfter: time.Second,                &#125;            &#125; else if ri &lt; 6 &#123;                err = AnotherErr&#123;                    err: &quot;another err&quot;,                &#125;            &#125;            if err == nil &#123;                defer func() &#123;                    if err := resp.Body.Close(); err != nil &#123;                        panic(err)                    &#125;                &#125;()                body, err = ioutil.ReadAll(resp.Body)            &#125;            return err        &#125;,        retry.DelayType(func(n uint, err error, config *retry.Config) time.Duration &#123;            switch e := err.(type) &#123;            case SomeErr:                return e.retryAfter            case AnotherErr:                return retry.BackOffDelay(n, err, config)            default:                return time.Second            &#125;        &#125;),        retry.OnRetry(func(n uint, err error) &#123; retrySum += 1 &#125;),        retry.RetryIf(func(err error) bool &#123;            switch err.(type) &#123;            case SomeErr, AnotherErr:                return true            default:                return false            &#125;        &#125;),        retry.Attempts(3),    )    assert.NoError(t, err)    assert.NotEmpty(t, body)&#125;</code></pre><h2 id="看看实现"><a href="#看看实现" class="headerlink" title="看看实现"></a>看看实现</h2><h3 id="声明-retry-行为"><a href="#声明-retry-行为" class="headerlink" title="声明 retry 行为"></a>声明 retry 行为</h3><pre><code class="golang">type RetryableFunc func() errorfunc Do(retryableFunc RetryableFunc, opts ...Option) error</code></pre><p><strong>这里声明了三部分内容：</strong></p><ol><li>Do 函数的执行核心 retryableFunc，一个会返回 error 的简单函数</li></ol><p>这里可以看出，待执行的任务会被 func() 包裹，没有额外的入参，但是可以抛出一个 error 作为任务异常的标志。后续重试行为依赖这个 error 信息</p><ol start="2"><li><p>Do 函数提供了扩展能力，此处用的是 Options 模式(可以看另一篇 <a href="/2020/12/28/go-pattern-options/" title="Go 设计模式之 Options-Pattern">Options-Pattern</a> 文章了解更多)</p></li><li><p>Do 函数返回了 error，此处描述的是整个 retry 结束过后，任务尚未成功，需要有一个结果</p></li></ol><h3 id="默认-retry-配置"><a href="#默认-retry-配置" class="headerlink" title="默认 retry 配置"></a>默认 retry 配置</h3><blockquote><p>从默认配置中探索 <code>retry-go</code> 库的设计思路</p></blockquote><pre><code class="golang">func newDefaultRetryConfig() *Config &#123;    return &amp;Config&#123;        attempts:      uint(10),        delay:         100 * time.Millisecond,        maxJitter:     100 * time.Millisecond,        onRetry:       func(n uint, err error) &#123;&#125;,        retryIf:       IsRecoverable,        delayType:     CombineDelay(BackOffDelay, RandomDelay),        lastErrorOnly: false,        context:       context.Background(),    &#125;&#125;</code></pre><p>当 Do 函数的 options 为空时，该配置就是实际执行 Do 函数的运行时配置了。罗列一下配置项：</p><ul><li>attempts -&gt; 重试次数，默认 10 次，使用 uint 限制重试次数大于 0</li><li>delay -&gt; 重试的间隔时间</li><li>maxJitter -&gt; RandomDelay 函数的 delay 最大值设置，随机范围在 <code>[0, maxJitter)</code> 之间</li><li>onRetry -&gt;  这是一个空函数，默认在每次重试前无动作</li><li>lastErrorOnly -&gt; 表示是否只收集最后一个 error，反之则收集全部任务产生的 error 信息</li><li>context -&gt; 设置一个无用的 context，但是可以传递一个具有超时配置的 context 进来，这样可以设置整个 retry 的全局超时时间</li><li>retryIf -&gt; 这是判断是否要进行重试的函数，<code>IsRecoverable</code> 作用如下:</li></ul><pre><code class="golang">func IsRecoverable(err error) bool &#123;    _, isUnrecoverable := err.(unrecoverableError)    return !isUnrecoverable&#125;</code></pre><p>可以看到这里当错误 err 是 <code>unrecoverableError</code> 时，就不会重试。也就是 retry-go 自定义了一个不可恢复的异常，同时提供了 <code>Unrecoverable</code>函数封装一个 <code>unrecoverableError</code>。如果用户知道了这个特性，就可以利用起来，从而中断重试。下面是 <code>unrecoverableError</code> 的定义:</p><pre><code class="golang">type unrecoverableError struct &#123;    error&#125;func Unrecoverable(err error) error &#123;    return unrecoverableError&#123;err&#125;&#125;</code></pre><ul><li>delayType -&gt;  设置延时时间的函数，组合了 BackOffDelay 指数级增长的延时和 RandomDelay 随机延时，从而达到总体上指数级增长但是具体数值又有波动的延时效果</li></ul><pre><code class="golang">// CombineDelay(BackOffDelay, RandomDelay),func CombineDelay(delays ...DelayTypeFunc) DelayTypeFunc &#123;    const maxInt64 = uint64(math.MaxInt64)    return func(n uint, err error, config *Config) time.Duration &#123;        var total uint64        for _, delay := range delays &#123;            total += uint64(delay(n, err, config))            if total &gt; maxInt64 &#123;                total = maxInt64            &#125;        &#125;        return time.Duration(total)    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/avast/retry-go&quot;&gt;retry-go&lt;/a&gt; 实现非常优美的 retry 库&lt;br&gt;2022/06/15 仿写实现同样的功能 &lt;a href=&quot;https://github.com</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
    <category term="Golang 开源系列" scheme="http://nickchenyx.github.io/tags/Golang-%E5%BC%80%E6%BA%90%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Golang 开源之 tparse 使用指南</title>
    <link href="http://nickchenyx.github.io/2022/06/12/golang-tparse-usage/"/>
    <id>http://nickchenyx.github.io/2022/06/12/golang-tparse-usage/</id>
    <published>2022-06-12T10:14:13.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/mfridman/tparse">tparse</a> 分析和归纳 <code>go test</code> 输出的命令行工具</p></blockquote><p><strong>安装</strong></p><pre><code class="shell">go install github.com/mfridman/tparse@latest</code></pre><h2 id="tparse-能做什么"><a href="#tparse-能做什么" class="headerlink" title="tparse 能做什么"></a>tparse 能做什么</h2><p>仅使用 <code>go test -v</code> 来显示测试结果，只是罗列了所有测试集合，没有归纳总结，不便于一眼明了。</p><pre><code class="shell">➜  go test -race ./testtparse -v=== RUN   Test_sum=== RUN   Test_sum/return_2--- PASS: Test_sum (0.00s)    --- PASS: Test_sum/return_2 (0.00s)=== RUN   Test_sub=== RUN   Test_sub/return_0--- PASS: Test_sub (0.00s)    --- PASS: Test_sub/return_0 (0.00s)PASSok      code.byted.org/demo/testtparse  0.026s</code></pre><p>使用  <code>tparse</code> 分析归纳 <code>go test</code> 的报告结论</p><pre><code class="shell">➜  go test -race ./testtparse -json -cover | tparse -all+--------+---------+-------------------+------------+| STATUS | ELAPSED |       TEST        |  PACKAGE   |+--------+---------+-------------------+------------+| PASS   |    0.00 | Test_sum          | testtparse || PASS   |    0.00 | Test_sum/return_2 | testtparse || PASS   |    0.00 | Test_sub          | testtparse || PASS   |    0.00 | Test_sub/return_0 | testtparse |+--------+---------+-------------------+------------++--------+---------+--------------------------------+--------+------+------+------+| STATUS | ELAPSED |            PACKAGE             | COVER  | PASS | FAIL | SKIP |+--------+---------+--------------------------------+--------+------+------+------+| PASS   | 0.04s   | code.byted.org/demo/testtparse | 100.0% |    4 |    0 |    0 |+--------+---------+--------------------------------+--------+------+------+------+</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/mfridman/tparse&quot;&gt;tparse&lt;/a&gt; 分析和归纳 &lt;code&gt;go test&lt;/code&gt; 输出的命令行工具&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;安装&lt;</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
    <category term="Golang 开源系列" scheme="http://nickchenyx.github.io/tags/Golang-%E5%BC%80%E6%BA%90%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Golang 单元测试之绕过 init panic</title>
    <link href="http://nickchenyx.github.io/2022/06/02/golang-init-panic-mock/"/>
    <id>http://nickchenyx.github.io/2022/06/02/golang-init-panic-mock/</id>
    <published>2022-06-02T06:59:48.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h2 id="init-函数中发生-panic"><a href="#init-函数中发生-panic" class="headerlink" title="init 函数中发生 panic"></a>init 函数中发生 panic</h2><p><strong>在做单元测试的时候，当程序引入的包内有 init 函数并且抛出了 panic，如何修复这种场景？</strong></p><p>第一反应肯定是能否 mock 掉出问题的函数，但是因为 mock 的执行顺序是在依赖包的 init 执行之后，所以 mock 生效前，init 函数就已经 panic 了。明显这样做是无效的。</p><p>以往的经验是在发生 panic 的 init 函数代码仓库中，新建一个测试分支，修改 init 中的逻辑避免 panic。然后再在单测代码中引入这个修复分支，才可以进行测试。<strong>在这里提供一个新的思路↓</strong></p><h2 id="利用-init-默认加载的顺序解决"><a href="#利用-init-默认加载的顺序解决" class="headerlink" title="利用 init 默认加载的顺序解决"></a>利用 init 默认加载的顺序解决</h2><p><strong>新的方案，利用 init 加载顺序的机制，在前置运行的 init 函数中，mock 会发生 panic 的 init 函数场景。</strong></p><p>我们尝试使用 init 加载顺序修复这个问题，如下的三个项目：</p><ol><li>import_panic_init 这个是苦主项目，他的引用了会产生 panic 的 init 函数的外部包</li><li>panic_init 会产生 panic 的 init 的函数所在地</li><li>util 无辜的工具库，被 panic_init 错误的使用产生了 panic<pre><code>.├── import_panic_init│   ├── a│   │   └── a.go│   ├── go.mod│   ├── go.sum│   └── main.go├── panic_init│   ├── go.mod│   └── panic_init.go└── util ├── go.mod └── util.go</code></pre>代码可以在仓库中获取：<a href="https://github.com/nickChenyx/code-repo/tree/main/golang/test_panic_init">https://github.com/nickChenyx/code-repo/tree/main/golang/test_panic_init</a></li></ol><p>在 util 包中，util.go 文件如下：</p><pre><code class="go">package utilimport &quot;fmt&quot;func IsTest(t *int) bool &#123;    fmt.Println(&quot;util.isTestCall&quot;)    if t == nil &#123;        panic(&quot;t can&#39;t be nil&quot;)    &#125;    return *t == 0&#125;</code></pre><p>在 panic_init 包中，panic_init.go 文件如下：</p><pre><code class="go">package panic_initimport &quot;fmt&quot;import &quot;util&quot;func init() &#123;    util.IsTest(nil) // 必定发生 panic    fmt.Println(&quot;panic_init run..&quot;)&#125;</code></pre><p>在 import_panic_init 包中，main.go 文件如下：</p><pre><code class="go">package mainimport (        &quot;fmt&quot;        _ &quot;panic_init&quot;        &quot;util&quot;        &quot;bou.ke/monkey&quot;)func main() &#123;        monkey.Patch(util.IsTest, func(t *int) bool &#123;                return true        &#125;)        fmt.Println(&quot;main run...&quot;)&#125;</code></pre><p>可以看到此处 main 函数妄图 mock util.IsTest 函数，避免 panic 影响 fmt.Println(“main run…”) 的执行。</p><p>但是运行结果是：</p><pre><code class="shell">$ go run main.go # 执行 import_panic_init.main 函数util.isTestCallpanic: t can&#39;t be nilgoroutine 1 [running]:util.IsTest(0x0)        .../projects/test_panic_init/util/util.go:8 +0x89panic_init.init.0()        .../projects/test_panic_init/panic_init/panic_init.go:7 +0x1b    exit status 2</code></pre><p>可以看到 main 函数中的 mock 实际上未生效。修改 main.go 文件如下：</p><pre><code class="go">package mainimport (        _ &quot;a&quot; // 添加了这个 a 包，并且在 panic_init 包之前引入！这很重要        &quot;fmt&quot;        _ &quot;panic_init&quot;        &quot;util&quot;        &quot;bou.ke/monkey&quot;)func main() &#123;        monkey.Patch(util.IsTest, func(t *int) bool &#123;                return true        &#125;)        fmt.Println(&quot;main run...&quot;)&#125;</code></pre><p>在 <code>import_panic_init/a/a.go</code> 中，定义了 mock 函数用于 mock util 包的函数如下：</p><pre><code class="go">package a import &quot;util&quot;import &quot;bou.ke/monkey&quot;import &quot;fmt&quot;func init() &#123;    monkey.Patch(util.IsTest, func(t *int) bool &#123;    return true    &#125;)    fmt.Printf(&quot;a init call util.IsTest: %v\n&quot;, util.IsTest(nil))&#125;</code></pre><p>然后再执行 main.go 如下：</p><pre><code class="shell">$ go run main.go # 执行 import_panic_init.maina inita init call util.IsTest: truepanic_init run..main run...</code></pre><p><strong>可以看到此时 a 包的 init 先于 panic_init 包的 init 执行，所以 mock 函数先被执行，panic_init 中的 util.IsTest 调用被 mock 返回 true，而不会发生 panic！</strong></p><p>有趣的是，如果将 main.go 中 import 的顺序调整，那么依然会发生 panic：</p><pre><code class="go">import (        &quot;fmt&quot;        _ &quot;panic_init&quot;        _ &quot;a&quot; // 在 panic_init 包之后引入，此时执行顺序在 panic_init 包之后        &quot;util&quot;        &quot;bou.ke/monkey&quot;)</code></pre><h2 id="Golang-的执行顺序"><a href="#Golang-的执行顺序" class="headerlink" title="Golang 的执行顺序"></a>Golang 的执行顺序</h2><blockquote><p><code>import --&gt; const --&gt; var --&gt; init()</code></p></blockquote><p>一个 golang 文件中执行的顺序如上，先执行文件中定义的 import 包中的逻辑，再执行 const 常量定义，再执行 var 变量定义，再执行 init 函数。</p><p>具体可看：<a href="https://learnku.com/go/t/47135">https://learnku.com/go/t/47135</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;init-函数中发生-panic&quot;&gt;&lt;a href=&quot;#init-函数中发生-panic&quot; class=&quot;headerlink&quot; title=&quot;init 函数中发生 panic&quot;&gt;&lt;/a&gt;init 函数中发生 panic&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;在做单元测试</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
    <category term="单元测试" scheme="http://nickchenyx.github.io/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"/>
    
    <category term="UnitTest" scheme="http://nickchenyx.github.io/tags/UnitTest/"/>
    
  </entry>
  
  <entry>
    <title>Golang 开源之 semgroup 使用指南</title>
    <link href="http://nickchenyx.github.io/2022/05/24/golang-semgroup-usage/"/>
    <id>http://nickchenyx.github.io/2022/05/24/golang-semgroup-usage/</id>
    <published>2022-05-24T03:32:21.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/fatih/semgroup">semgroup</a> 用于并发执行一组任务，提供限制协程数量、同步等待任务执行完成及错误信息传递的能力。不同于 <a href="https://pkg.go.dev/golang.org/x/sync/errgroup">errgroup</a> ，semgroup 会执行所有任务，且收集任务产生的 error 信息。在全部任务执行完成后，将收集的 error 信息返回给开发者。</p></blockquote><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><blockquote><p>快速使用请看官网的使用方法，此处不赘述</p></blockquote><p>示例 <code>TestDemo</code> 中用到了如下功能，可以按需使用</p><ol><li><p><code>context</code> 定义了超时时间，可以限制整个任务的执行时间</p></li><li><p>任务并行执行，且向外丢出了自定义 error</p></li><li><p>使用 <code>errors.Is</code> 和 <code>errors.As</code> 处理 error</p></li><li><p>使用了拓展的 <code>ExportMultiError</code> 函数将所有内部错误全部输出（附带错误中包含了关键信息如 <code>taskId</code>，可以在后续的程序中使用）</p><pre><code class="go">func TestDemo(t *testing.T) &#123; // 可控制任务整体的执行时间 timedCtx, cancel := context.WithTimeout(context.Background(), time.Hour) defer cancel() g := NewGroup(timedCtx, 1) fe := fooErr&#123;taskId: 1, msg: &quot;__foo__&quot;&#125; g.Go(func() error &#123; return fe &#125;) g.Go(func() error &#123; return os.ErrClosed &#125;) g.Go(func() error &#123; return nil &#125;) err := g.Wait() if err == nil &#123;     t.Fatalf(&quot;g.Wait() should return an error&quot;) &#125; var (     fbe fooErr ) // Is 可用于抛出错误的判断 if !errors.Is(err, fe) &#123;     t.Errorf(&quot;error should be equal fooErr&quot;) &#125; // Is 可用于抛出错误的判断 if !errors.Is(err, os.ErrClosed) &#123;     t.Errorf(&quot;error should be equal os.ErrClosed&quot;) &#125; // As 可以将错误检索出来 if !errors.As(err, &amp;fbe) &#123;     t.Error(&quot;error should be matched foobarErr&quot;) &#125; // 通过上面 As 将错误信息取出，应该可以拿到失败的任务 id if fbe.taskId != 1 &#123;     t.Error(&quot;fooErr task id should be 1&quot;) &#125; me, isMultiError := ExportMultiError(err) if !isMultiError &#123;     t.Error(&quot;err should be a multiError&quot;) &#125; for _, e := range me &#123;     t.Logf(&quot;range me: %v&quot;, e)     var fe fooErr     if errors.As(e, &amp;fe) &amp;&amp; fe.taskId != 1 &#123;         t.Error(&quot;variable t.taskId should be 1&quot;)     &#125; &#125;&#125;</code></pre></li></ol><p>补充上文使用到的 <code>ExportMultiError</code> 函数。</p><pre><code class="go">func ExportMultiError(err error) ([]error, bool) &#123;    if err == nil &#123;        return nil, false    &#125;    switch err.(type) &#123;    case multiError:        return err.(multiError), true    default:        return []error&#123;err&#125;, false    &#125;&#125;</code></pre><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>并行处理失败的任务有无必要返回具体的信息？原库中仅透出了 <code>errors.Is</code> 和 <code>errors.As</code> 两个函数供处理异常，实际上会不会在 <code>error</code> 中透出具体的任务信息，供错误失败时使用呢？<br>基于这种思考，先提供了一个 <code>ExportmultiError</code> 的函数解决这个问题。有无更好的方式，或者业界更通用的处理方案？</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/fatih/semgroup&quot;&gt;semgroup&lt;/a&gt; 用于并发执行一组任务，提供限制协程数量、同步等待任务执行完成及错误信息传递的能力。不同于 &lt;a href=&quot;https://pkg.g</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
    <category term="Golang 开源系列" scheme="http://nickchenyx.github.io/tags/Golang-%E5%BC%80%E6%BA%90%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Golang 开源之 try 使用指南</title>
    <link href="http://nickchenyx.github.io/2022/05/10/golang-try-usage/"/>
    <id>http://nickchenyx.github.io/2022/05/10/golang-try-usage/</id>
    <published>2022-05-10T12:20:44.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>Try</strong>(<a href="https://github.com/dsnet/try">https://github.com/dsnet/try</a>)  go1.18 后一种新的 panic 处理方式</p></blockquote><blockquote><p>错误处理 —— Error Handling</p></blockquote><p><strong>Try</strong> 在 Golang 中实现了一种极简的错误处理方式。<br>不过这里需要明确一点使用前提，必须是 Go1.18 以上的泛型版本才可以使用此库。</p><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><p><strong>回顾 Golang 标准错误处理流程</strong><br>作为比较，先放一下 Golang 中标准的错误处理流程。</p><pre><code class="go">type Duck struct &#123;    Age int&#125;func main() &#123;    duck := Duck&#123;Age:1&#125;    bs, err := json.Marshal(&amp;duck)    if err != nil &#123;        log.Fatal(&quot;marshal duck fail&quot;)        return    &#125;    var dummy Duck    err = json.Unmarshal(bs, &amp;dummy)    if err != nil &#123;        log.Fatal(&quot;unmarshal duck fail&quot;)        return    &#125;    fmt.Printf(&quot;dummy: %+v&quot;, dummy)&#125;</code></pre><p>标准的 Goland Error Handling 实在是有点繁琐，每次 err 都需要单独判断，频繁的 if 逻辑穿插在业务处理流程当中。</p><p><strong>如何能够像类似  Java Try-Catch 一样的错误处理方式呢？</strong></p><p><strong>使用 Try 进行错误处理</strong></p><p>现在我们尝试使用 <strong>Try</strong> 来编写以上代码：</p><pre><code class="go">type Duck struct &#123;    Age int&#125;func main() &#123;    defer try.F(log.Fatal)    duck := Duck&#123;Age:1&#125;    bs := try.E1(json.Marshal(&amp;duck))    var dummy Duck    try.E(json.Unmarshal(bs, &amp;dummy))    fmt.Printf(&quot;dummy: %+v&quot;, dummy)&#125;</code></pre><p>太干净了！可以看到主流程都非常紧密的连接在一起了，错误处理已经被 <strong>Try</strong> 给包裹住，不需要再使用烦人的 <code>if err!= nil</code> 语句了。</p><h2 id="Try-API-解析"><a href="#Try-API-解析" class="headerlink" title="Try API 解析"></a>Try API 解析</h2><blockquote><p> 开发文档地址 <a href="https://pkg.go.dev/github.com/dsnet/try">https://pkg.go.dev/github.com/dsnet/try</a></p></blockquote><p><strong>全量 API 列表</strong></p><pre><code class="go">func E(err error)func E1(a A, err error) Afunc E2(a A, b B, err error) (A, B)func E3(a A, b B, c C, err error) (A, B, C)func E4(a A, b B, c C, d D, err error) (A, B, C, D)func F(fn func(...any))func Handle(errptr *error)func HandleF(errptr *error, fn func())func Recover(fn func(err error, frame runtime.Frame))</code></pre><p>通过 API 可以发现 <strong>Try</strong> 的设计：</p><ol><li>函数 <code>E()</code> 是核心，主要用来包裹返回参数 <code>error</code>。多个函数 <code>E()</code> 是因为需要匹配不同数量的返回值。<ul><li>使用了泛型去匹配非 error 类型的变量，所以必须要 Go1.18 以上才可使用</li><li>error 都是在末位，所以函数 <code>E()</code> 只能支持 error 在最后一位的函数返回值作为入参</li><li>如果需要有更长数量返回值的函数，或 error 位置不在最后一位的函数，可以新增函数 <code>E()</code> 来适配</li></ul></li><li>函数 <code>F(fn func(...any))</code> 实际上接收的是一个函数，函数的入参是可变长的 any 类型，“入门”一节中使用的 log.Fatal 就是这类函数</li><li>函数 <code>Handle(errptr *error)</code> 接收了一个 error 指针，这里的使用方式是，将拦截到的 error 信息可以赋值到 errptr 指针处，后面介绍一个用法</li><li>函数 <code>HandleF(errptr *error, fn func())</code> 接受了一个 error 指针的同时，也提供了一个处理函数，这个处理函数会在 error 赋值到 errptr 指针后进行，后面补充用法</li><li>函数 <code>Recover(...)</code> 可以看到接受了一个函数，可以同时处理 error 和栈帧信息</li></ol><p><strong>函数 Handler 使用</strong></p><pre><code class="go">func f() (err error) &#123;    defer try.Hander(&amp;err)    try.E(...)    ...&#125;</code></pre><p>可以看到此处函数 <code>Handler</code> 接收了 函数 <code>f</code> 的返回参数中的 err 变量地址作为入参，此时如果 <code>try.E</code> 中拦截到了 error，会将这个 error 信息赋值到返回参数的 err 变量中，<strong>实现了错误的传递</strong>。</p><p><strong>函数 HandlerF 使用</strong></p><pre><code>func f() (err error) &#123;    defer try.HandlerF(&amp;err, func() &#123;        err = fmt.Errorf(&quot;f() call err: %w&quot;, err)    &#125;)    try.E(...)    ...&#125;</code></pre><p>函数 <code>HandlerF</code> 的一个功能是将 error 传递到函数 <code>f</code> 的返回参数 err 中；另一个能力是接收一个自定义函数。假定的一个场景是：在这个自定义函数中，对传递的 error 进行一次 wrap，增加上一些额外信息 <code>f() call err:</code>，这样可以标识错误传递来源是函数<code>f</code> 。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>panic and recover </p><pre><code class="go">func f() &#123;    defer recover()    panic(&quot;^_^&quot;)&#125;</code></pre><p><strong>Try</strong> 利用了 Golang 提供的 panic &amp; recover 的能力，巧妙的将业务逻辑中的 error 信息包装成 panic，随后被 defer 中的 recover 捕获，从而完成中断业务处理，返回错误信息的能力。</p><p>以函数 <code>Handler(errptr *error)</code> 举例，代码中对 panic 操作进行了 recover，并且只有 panic 的信息会 error 对象时，才捕获并转移到 errptr 中。</p><pre><code class="go">func Handle(errptr *error) &#123;    r := recover()    switch r.(type) &#123;        case nil:        case error:            *errptr = r.(error)        default:            panic(r)    &#125;&#125;</code></pre><p>以上代码存在的问题是，recover 出来的 error 可能并不是 <code>try.E()</code> 函数 panic 抛出的，所以上文定义的 <code>Handler()</code> 执行下来会存在将其他代码片段出现的 panic error 一并处理了。这超出了 <strong>Try</strong> 职能的范围。所以在 <strong>Try</strong> 的实现中，实际上是自定义了一个 error 类型—— <code>wrapError</code> ，这样在 switch type 判断中，明确判断是否是 <code>wrapError</code> 即可准确的处理 <strong>Try</strong> 函数中抛出的 error。</p><pre><code class="go">type wrapError struct &#123;    error    pc [1]uintptr&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Try&lt;/strong&gt;(&lt;a href=&quot;https://github.com/dsnet/try&quot;&gt;https://github.com/dsnet/try&lt;/a&gt;)  go1.18 后一种新的 panic 处理方式&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
    <category term="Golang 开源系列" scheme="http://nickchenyx.github.io/tags/Golang-%E5%BC%80%E6%BA%90%E7%B3%BB%E5%88%97/"/>
    
    <category term="泛型" scheme="http://nickchenyx.github.io/tags/%E6%B3%9B%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>dsq 和 jq 操作记录</title>
    <link href="http://nickchenyx.github.io/2022/03/11/local-file-process/"/>
    <id>http://nickchenyx.github.io/2022/03/11/local-file-process/</id>
    <published>2022-03-11T12:12:27.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本地文件处理工作流整理，待归档到一个合适的目录</p></blockquote><h2 id="通过-dsq-join-文件条件查找"><a href="#通过-dsq-join-文件条件查找" class="headerlink" title="通过 dsq join 文件条件查找"></a>通过 dsq join 文件条件查找</h2><p>安装工具</p><ul><li><code>brew install dsq</code>, <a href="https://github.com/multiprocessio/dsq">dsq github</a></li><li><code>brew install jq</code>, <a href="https://github.com/stedolan/jq">jq github</a></li></ul><pre><code class="json">// 文件 a.json[    &#123;&quot;type&quot;: &quot;tool&quot;, &quot;id&quot;: &quot;1&quot;&#125;,    &#123;&quot;type&quot;: &quot;tool&quot;, &quot;id&quot;: &quot;2&quot;&#125;,    &#123;&quot;type&quot;: &quot;tool&quot;, &quot;id&quot;: &quot;3&quot;&#125;,    &#123;&quot;type&quot;: &quot;book&quot;, &quot;id&quot;: &quot;1&quot;&#125;,    &#123;&quot;type&quot;: &quot;none&quot;, &quot;id&quot;: &quot;1&quot;&#125;]// 文件 b.json[    &#123;&quot;author&quot;: &quot;nickchen&quot;, &quot;type&quot;:&quot;tool&quot;, &quot;tag&quot;:[1,2,3]&#125;,    &#123;&quot;author&quot;: &quot;whoru&quot;, &quot;type&quot;:&quot;none&quot;&#125;,    &#123;&quot;author&quot;: &quot;teacher&quot;, &quot;type&quot;:&quot;book&quot;&#125;]</code></pre><p><strong>需求打印出 author、type、id ，且 id=1 的组合</strong></p><ol><li>因为 dsq 没法解析内嵌列表，所有 b.json 中的 tag 字段必须要被删除</li><li>需要 dsq join a.json 和 b.json，且判断 id = 1</li><li>打印结果确认是否符合要求</li><li>输出一个格式化的 json array</li></ol><p>开始执行：</p><ol><li>清理 b.json 中的 tag 字段<ul><li>jq 的最外侧 <code>[]</code> 是列表构造器，会生成一份列表</li><li>jq 的 <code>.[]</code> 代表迭代器，迭代当前这个 json array</li><li>jq 的 <code>|</code> 是 pipe 管道，将数据流转到下一个程序</li><li>jq 的 <code>del()</code> 是内建函数，可以删除某个字段</li></ul></li></ol><pre><code class="shell">➜  cat b.json | jq &#39;[.[]|del(.tag)]&#39; &gt; c.jsonor➜  cat b.json | jq &#39;[.[]|&#123;author:.author,type:.type&#125;]&#39; &gt; c.json</code></pre><ol start="2"><li>dsq join 查询 &amp; 打印结果<ul><li>dsq 的 <code>--pretty</code> 可以输出表格结果</li><li>dsq 输入多个文件，可以按照进行 join 操作，表名即文件顺序</li></ul></li></ol><pre><code class="shell">➜  dsq --pretty a.json c.json &quot;select &#123;0&#125;.id, &#123;1&#125;.type, &#123;1&#125;.author from &#123;0&#125; join &#123;1&#125; on &#123;0&#125;.type = &#123;1&#125;.type where &#123;0&#125;.id = 1&quot;+----------+----+------+|  author  | id | type |+----------+----+------+| nickchen |  1 | tool || teacher  |  1 | book || whoru    |  1 | none |+----------+----+------+</code></pre><ol start="3"><li>输出一个格式化的 json array</li></ol><pre><code class="shell">➜  dsq a.json c.json &quot;select &#123;0&#125;.id, &#123;1&#125;.type, &#123;1&#125;.author from &#123;0&#125; join &#123;1&#125; on &#123;0&#125;.type = &#123;1&#125;.type where &#123;0&#125;.id = 1&quot; | jq .[  &#123;    &quot;id&quot;: &quot;1&quot;,    &quot;type&quot;: &quot;tool&quot;,    &quot;author&quot;: &quot;nickchen&quot;  &#125;,  &#123;    &quot;type&quot;: &quot;book&quot;,    &quot;author&quot;: &quot;teacher&quot;,    &quot;id&quot;: &quot;1&quot;  &#125;,  &#123;    &quot;id&quot;: &quot;1&quot;,    &quot;type&quot;: &quot;none&quot;,    &quot;author&quot;: &quot;whoru&quot;  &#125;]</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本地文件处理工作流整理，待归档到一个合适的目录&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;通过-dsq-join-文件条件查找&quot;&gt;&lt;a href=&quot;#通过-dsq-join-文件条件查找&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="工具" scheme="http://nickchenyx.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="jq" scheme="http://nickchenyx.github.io/tags/jq/"/>
    
    <category term="dsq" scheme="http://nickchenyx.github.io/tags/dsq/"/>
    
    <category term="文件处理" scheme="http://nickchenyx.github.io/tags/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Go 设计模式之 Options-Pattern</title>
    <link href="http://nickchenyx.github.io/2020/12/28/go-pattern-options/"/>
    <id>http://nickchenyx.github.io/2020/12/28/go-pattern-options/</id>
    <published>2020-12-28T02:36:01.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<p>Options Pattern 主要是使用于装配属性，让我们先来看看传统的属性装配方案。</p><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><pre><code class="go">type House struct &#123;    Material     string    HasFireplace bool    Floors       int&#125;</code></pre><h2 id="通过构造函数-Constructor-装配属性"><a href="#通过构造函数-Constructor-装配属性" class="headerlink" title="通过构造函数(Constructor)装配属性"></a>通过构造函数(Constructor)装配属性</h2><pre><code class="go">// NewHouse(&quot;concrete&quot;, 5, true)func NewHouse(m string, f int, fp bool) *House &#123;    return &amp;House &#123;        Material: m,        HasFireplace: fp,        Floors: f,    &#125;&#125;</code></pre><p>可以看到此时通过一个自定义的构造函数装配属性，此时需装配的属性需要一次性全部填入，且构造函数的入参有顺序性，必须按照函数定义的顺序传入参数。另外，当需装配的属性过于多时，此时构造函数也会越来越冗长。</p><h2 id="通过-func-作为参数传入构造函数"><a href="#通过-func-作为参数传入构造函数" class="headerlink" title="通过 func 作为参数传入构造函数"></a>通过 func 作为参数传入构造函数</h2><pre><code class="go">type HouseOption func(*House)func WithConcrete() HouseOption &#123;    return func(h *House) &#123;        h.Material = &quot;concrete&quot;    &#125;&#125;func WithoutFireplace() HouseOption &#123;    return func(h *House) &#123;        h.HasFireplace = false    &#125;&#125;func WithFloors(floors int) HouseOption &#123;    return func(h *House) &#123;        h.Floors = floors    &#125;&#125;func NewHouse(opts ...HouseOption) *House &#123;    const (        defaultFloors       = 2        defaultHasFireplace = true        defaultMaterial     = &quot;wood&quot;    )    h := &amp;House&#123;        Material:     defaultMaterial,        HasFireplace: defaultHasFireplace,        Floors:       defaultFloors,    &#125;    // Loop through each option    for _, opt := range opts &#123;        // Call the option giving the instantiated        // *House as the argument        opt(h)    &#125;    // return the modified house instance    return h&#125;// build House with optionsh := NewHouse(  WithConcrete(),  WithoutFireplace(),  WithFloors(3),)</code></pre><p>将 func 作为参数传入，一是方便了装配属性的复杂配置，二是不需要固定顺序的构造参数传入，三其实这样的实现方式也可以作为一个属性装配的切面，可以暗搓搓整点活儿。</p><p>这就是 Options Patter 了。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ul><li><a href="https://www.sohamkamani.com/golang/options-pattern/">https://www.sohamkamani.com/golang/options-pattern/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Options Pattern 主要是使用于装配属性，让我们先来看看传统的属性装配方案。&lt;/p&gt;
&lt;h2 id=&quot;结构体&quot;&gt;&lt;a href=&quot;#结构体&quot; class=&quot;headerlink&quot; title=&quot;结构体&quot;&gt;&lt;/a&gt;结构体&lt;/h2&gt;&lt;pre&gt;&lt;code class=</summary>
      
    
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/categories/Golang/"/>
    
    
    <category term="Golang" scheme="http://nickchenyx.github.io/tags/Golang/"/>
    
    <category term="Pattern" scheme="http://nickchenyx.github.io/tags/Pattern/"/>
    
    <category term="设计模式" scheme="http://nickchenyx.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Docker 中的 Java 运行时内存限制配置</title>
    <link href="http://nickchenyx.github.io/2020/12/25/java-docker-setup/"/>
    <id>http://nickchenyx.github.io/2020/12/25/java-docker-setup/</id>
    <published>2020-12-25T02:14:34.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>现在是2020年12月，在这个时间点 Java 在 Docker 容器中运行的内存限制已经有了明确的解决方案，此处做个记录。</p></blockquote><p>JDK 10 引入了默认开启的参数 <code>UseContainerSupport</code>，同时这个特性也被 backport 到 JDK1.8 的 8u191 版本。也就是说 8u191 和更后面的 JDK 都可以通过开启 <code>UseContainerSupport</code> 来支持 cgroup 看到 cgroup 的内存限制。<br>再结合 <code>MaxRAMPercentage</code> 来动态算一个堆内存上限就足够了，这个值具体看服务用到的堆外内存和线程的使用量，一般无脑给个 75/80 都没问题。具体程序用多少内存合适，正确实践一定是先预估一个偏保守的值，在环境里跑一下，然后结合实际请求量和监控来持续调节 kubernetes/docker 的内存限制数值。</p><p>下面是个 spring boot(layered jar) 工程打包为镜像的 Dockerfile 示例</p><pre><code>FROM openjdk:15WORKDIR applicationCOPY ./dependencies/ ./COPY ./spring-boot-loader/ ./COPY ./snapshot-dependencies/ ./COPY ./application/ ./ENV JAVA_OPTS=&#39;-Dspring.application.name=my-demo \-XX:+UseContainerSupport \-XX:MaxRAMPercentage=75.0 &#39;ENTRYPOINT exec java $JAVA_OPTS org.springframework.boot.loader.JarLauncher</code></pre><p>最后还要再额外留意下，自 jdk9 (8u131)开始，这些跟容器支持的参数有过几轮变迁。如果没有多关注 upstream 或者搜了国内 CSDN 低劣二手文，很容易被拐到坑里去，比如看到下面这些参数，基本都是废弃或用不到的，不用再理会：</p><pre><code>UnlockExperimentalVMOptionsUseCGroupMemoryLimitForHeapUseCGroupMemoryLimitMaxRAMFractionMaxRAM</code></pre><p>—— 引用自：李飘柔 <a href="https://www.zhihu.com/question/315793102/answer/1639340828">https://www.zhihu.com/question/315793102/answer/1639340828</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;现在是2020年12月，在这个时间点 Java 在 Docker 容器中运行的内存限制已经有了明确的解决方案，此处做个记录。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;JDK 10 引入了默认开启的参数 &lt;code&gt;UseContainerSupp</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Java" scheme="http://nickchenyx.github.io/tags/Java/"/>
    
    <category term="Docker" scheme="http://nickchenyx.github.io/tags/Docker/"/>
    
    <category term="JVM" scheme="http://nickchenyx.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>记一次端口扫描工具实现</title>
    <link href="http://nickchenyx.github.io/2020/11/17/dial/"/>
    <id>http://nickchenyx.github.io/2020/11/17/dial/</id>
    <published>2020-11-17T06:33:02.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h2 id="端口扫描工具"><a href="#端口扫描工具" class="headerlink" title="端口扫描工具"></a>端口扫描工具</h2><p>工具如其名，主要功能是扫描服务器端口是否开放。常用的方式是扫描服务器(S)在某一段端口(P)范围内，有哪些端口正在被监听。</p><p>如：扫描服务器 127.0.0.1，端口 [80, 2000）段内，查看被监听的端口。</p><h3 id="实现方案"><a href="#实现方案" class="headerlink" title="实现方案"></a>实现方案</h3><ul><li>和对端服务器端口尝试建立 socket 链接，如果链接成功建立，则表明该端口正在被监听。</li><li>使用多线程方案，加快端口扫描速度</li><li>使用协程方案，降低资源使用，加快扫描速度</li></ul><p>以上就是大致的是实现步骤。本次实现了 </p><ul><li>Java 单线程扫描</li><li>Java 多线程扫描</li><li>Java 协程扫描</li><li>Rust 协程扫描</li></ul><p>没错，&gt;..&lt; 实际上这是一次学习 Java Quasar Fiber 和 Rust 过程中的小练习。</p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><ul><li>Java 实现<a href="https://github.com/nickChenyx/jdial">🔗</a></li><li>Rust 实现<a href="https://github.com/nickChenyx/rdial">🔗</a></li></ul><p>实现已放在 github 仓库，感兴趣的可以下载自行运行。</p><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><p>Java Fiber 和 Rust 的实现过程中都遇到了关于协程使用上的问题，在此记录一下。</p><h4 id="Java-Fiber"><a href="#Java-Fiber" class="headerlink" title="Java Fiber"></a>Java Fiber</h4><p>首先需要在函数上标明 <code>@Suspendable</code>，协程内的阻塞函数需要标记此注解才能让协程正常服务。</p><p>其次协程中使用的阻塞函数，需要有自己的封装实现。线程方式中使用 <code>java.net.Socket#connect</code> 函数是调用的 JDK 原生实现 <code>java.net.PlainSocketImpl#socketConnect</code>。<br>这个实现是阻塞的，此阻塞的实现，会影响阻塞住协程，使得协程的性能无法发挥。<br>Quasar 为此单独提供了 <code>FiberSocketChannel</code> 实现，此实现调用了 <code>co.paralleluniverse.fibers.io.AsyncFiberSocketChannel#connect</code>，<br>底层是异步 IO 实现，使用 <code>Fiber.park</code> 接替了原有的阻塞实现。</p><p>使用过程中可以感受到，使用 Fiber 接替现有的代码，还是有需要改造的部分，无法零成本接入。（<strong>此处如果我有使用不合理的地方，请邮件我改进，谢谢</strong>）</p><h4 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h4><p>Rust 版本实现中，使用了三方依赖 may 作为 coroutine 的实现依赖。出现了同 Java 版本类似的问题。<br>原生的 <code>std::net::TcpStream</code> 依然会阻塞住协程，还是需要使用 may 提供的异步 IO 实现 <code>may::net::TcpStream</code> 才能匹配协程提升性能。</p><p>另外就是 Rust 的 <code>TcpStream::connect_timeout</code> 使用方式不能按照官方提供的文档使用。</p><pre><code class="rust">use std::net::TcpStream;if let Ok(stream) = TcpStream::connect(&quot;127.0.0.1:8080&quot;) &#123;    println!(&quot;Connected to the server!&quot;);&#125; else &#123;    println!(&quot;Couldn&#39;t connect to server...&quot;);&#125;</code></pre><p>按照此方法使用 <code>TcpStream::connect_timeout</code>，会导致 if 判断提前进入 else 逻辑，造成逻辑异常。<br>必须将链接建立的语句提前，才能逻辑正常。</p><pre><code class="rust">// 正确实现let stream = TcpStream::connect_timeout(&amp;addrs[0], timeout);if stream.is_ok() &#123;    stream.unwrap().shutdown(Shutdown::Both).expect(&quot;shutdown tcp stream fail&quot;);    return true;&#125; else &#123;    return false;&#125;</code></pre><p><strong>诡异的问题</strong></p><p>实现 Rust 版本的测试结果中，出现了诡异的问题。问题描述如下：</p><pre><code class="txt">使用 rdial --start-port 80 --end-port 9000 --hostname 127.0.0.1 --timeout 200 执行时，结果返回了 [1080, 4198] 两个接口，实际上 6394 接口也是在被监听，但没有被扫描出来。修改使用 rdial --start-port 6000 --end-port 9000 --hostname 127.0.0.1 --timeout 200 执行时，此时结果返回了 6394 接口。</code></pre><p>经过 debug 确认了所有端口都有的的确确被扫描到，并没有漏掉 6394 端口。</p><p>继续尝试增加 timeout 超时时间，发现还是无法扫描到 6394 端口，但是有个特殊现象——6394 端口在建立链接语句执行后，立马返回了“close”日志，并没有经过设置好的等待时间。</p><p>最后发现问题是在操作系统限制的 fd 上，使用 <code>ulimit -n</code> 发现此时设置为 4864，可以看到我们的扫描程序第一次执行的确扫描到了 4198 这个接口监听，而忽略了 6394 这个接口。</p><p>答案呼之欲出，执行 <code>ulimit -n 10000</code> 将 fd 限制提升到 10000 之后再次执行，此时返回结果 <code>[1080, 4198, 6394]</code>，问题解决。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;端口扫描工具&quot;&gt;&lt;a href=&quot;#端口扫描工具&quot; class=&quot;headerlink&quot; title=&quot;端口扫描工具&quot;&gt;&lt;/a&gt;端口扫描工具&lt;/h2&gt;&lt;p&gt;工具如其名，主要功能是扫描服务器端口是否开放。常用的方式是扫描服务器(S)在某一段端口(P)范围内，有哪些端</summary>
      
    
    
    
    <category term="工具" scheme="http://nickchenyx.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="rust" scheme="http://nickchenyx.github.io/tags/rust/"/>
    
    <category term="coroutine" scheme="http://nickchenyx.github.io/tags/coroutine/"/>
    
    <category term="fiber" scheme="http://nickchenyx.github.io/tags/fiber/"/>
    
    <category term="quasar" scheme="http://nickchenyx.github.io/tags/quasar/"/>
    
    <category term="dial" scheme="http://nickchenyx.github.io/tags/dial/"/>
    
  </entry>
  
  <entry>
    <title>vim lsp 安装配置</title>
    <link href="http://nickchenyx.github.io/2020/11/10/vim-lsp-ready/"/>
    <id>http://nickchenyx.github.io/2020/11/10/vim-lsp-ready/</id>
    <published>2020-11-10T02:26:08.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>基于 <a href="https://github.com/Microsoft/language-server-protocol">Language Server Protocol</a> 通用协议作为支撑，结合各语言的 server 支持，以 vim 作为 client，完成在 vim 上进行编程语言开发。</p></blockquote><h2 id="vim-lsp-方案"><a href="#vim-lsp-方案" class="headerlink" title="vim-lsp 方案"></a>vim-lsp 方案</h2><p>使用插件 <a href="https://github.com/prabirshrestha/vim-lsp">vim-lsp</a>，结合 <a href="https://github.com/mattn/vim-lsp-settings">vim-lsp-settings</a> 作为实现方案。</p><pre><code class="shell">&quot; 使用vim-plug 插件管理工具安装，使用指南 https://vimjc.com/vim-plug.htmlPlug &#39;prabirshrestha/vim-lsp&#39;Plug &#39;mattn/vim-lsp-settings&#39;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;基于 &lt;a href=&quot;https://github.com/Microsoft/language-server-protocol&quot;&gt;Language Server Protocol&lt;/a&gt; 通用协议作为支撑，结合各语言的 server 支持，以 </summary>
      
    
    
    
    <category term="vim" scheme="http://nickchenyx.github.io/categories/vim/"/>
    
    
    <category term="vim" scheme="http://nickchenyx.github.io/tags/vim/"/>
    
  </entry>
  
  <entry>
    <title>Vim 学习笔记</title>
    <link href="http://nickchenyx.github.io/2020/11/01/vim-learning/"/>
    <id>http://nickchenyx.github.io/2020/11/01/vim-learning/</id>
    <published>2020-11-01T09:01:00.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><p><strong>删除</strong></p><ul><li><p>dw = daw</p></li><li><p>daw 删除单词及旁边空格</p></li><li><p>diw 删除单词</p></li><li><p>dt( 删除直到左括号</p></li><li><p>dt” 如上</p></li><li><p>d0 删除到行首</p></li><li><p>d$ 删除到行尾</p></li><li><p>ndd 删除 n 行</p></li><li><p>nx 删除 n 个字符</p></li></ul><p><strong>替换</strong></p><ul><li><p>r replace</p></li><li><p>c change</p></li><li><p>s substitute 删除当前字符并进入插入模式</p></li><li><p>R 不断替换后续字符，覆盖写</p></li><li><p>S 整行删除进入插入模式</p></li><li><p>ns 删除n个字符并进入插入模式</p></li><li><p>caw 删除当前单词并进入插入模式</p></li><li><p>ct” 删除直到”并进入插入模式</p></li></ul><p><strong>查询</strong></p><ul><li>/ 前向</li><li>? 反向</li><li>n/N 上下移动</li><li>*/# 对当前单词进行前向反向匹配</li></ul><p><strong>buffer 切换</strong></p><ul><li><p>:bprevious</p></li><li><p>:bnext</p></li><li><p>:bfirst</p></li><li><p>:blast</p></li><li><p>:b n 跳转 buffer</p></li><li><p>:b file_name 跳转 buffer</p></li><li><p>:ls 展示 buffer 列表</p></li><li><p>:e 打开编辑文件</p></li></ul><p><strong>window</strong></p><ul><li><p>:sp [file_name] 水平分隔</p></li><li><p>:vs [file_name] 垂直分隔</p></li><li><p><C-w> H/L 窗口左右替换</p></li><li><p><C-w>= 所有窗口等宽高</p></li></ul><p><strong>Tabpage</strong></p><ul><li>:tabnew [file_name] 新建一个标签页</li><li>gt 切换下一个 tab</li><li>gT 切换上一个 tab</li></ul><p><strong>宏录制</strong></p><ol><li>在 normal 模式下，按 q{register} 设置宏存放的寄存器位置，例如 qa，将宏存放在寄存器 a</li><li>开始进行 vim 操作</li><li>回到 normal 模式下，再按 q 结束录制</li><li>在 normal 模式下，按 @a 执行寄存器 a 中录制好的宏，可以利用100@a 执行一百次</li></ol><p><strong>复制黏贴</strong></p><ul><li>yy 默认复制一行到无名寄存器</li><li>p 默认粘贴无名寄存器的字符</li><li>寄存器 0 为复制寄存器，使用 y 复制文本会将内容同步保存到寄存器 0</li><li>:reg a 查看寄存器 a 中信息</li><li>:reg {register} 同上</li><li>“{register} 使用某寄存器(register a-z 都可以使用）</li><li>“{register}yy 复制一行并将结果存放到寄存器 {register}</li><li>“{register}p 粘贴寄存器 {register} 中的字符</li><li>“+ 使用系统剪贴板</li><li>设置 set clipboard=unnamed 默认使用系统剪贴板作为无名寄存器（Mac 需要使用 vim –version 检查是否支持 +clipboard 才有效）</li><li>在 insert 模式下，使用 <C-r> {register} 可以粘贴指定寄存器的内容</li></ul><p><strong>补全</strong></p><ul><li>根据 Ctrl-n、Ctrl-p 补全单词</li><li>根据 Ctrl-x Ctrl-f 补全文件名</li><li>根据 Ctrl-x Ctrl-o 补全代码，需要开启文件类型检查</li></ul><p><strong>更换配色主题</strong></p><ul><li>:colorscheme 显示当前主题</li><li>:colorscheme <C-d> 查看可选主题</li><li>:colorscheme &lt;主题名&gt; 更改主题</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;删除&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;dw = daw&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;daw 删除单词及旁边空格&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;diw 删除单词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;dt( 删</summary>
      
    
    
    
    <category term="vim" scheme="http://nickchenyx.github.io/categories/vim/"/>
    
    
    <category term="vim" scheme="http://nickchenyx.github.io/tags/vim/"/>
    
  </entry>
  
  <entry>
    <title>Linux 服务器负载(load)过高排查</title>
    <link href="http://nickchenyx.github.io/2020/11/01/linux-load-high/"/>
    <id>http://nickchenyx.github.io/2020/11/01/linux-load-high/</id>
    <published>2020-11-01T06:10:54.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2 id="load-avg"><a href="#load-avg" class="headerlink" title="load avg"></a>load avg</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Load_(computing)">服务器负载 load Wiki 解释</a></p></blockquote><p>服务器负载实际上指的就是当前操作系统 Running(执行中) 及 Runnable(就绪等待执行) 的任务队列数量(实际情况可能会包含其他，参看 wiki)，实际展示了当前系统执行的压力——如果就绪执行的队列过长，那么任务执行的周期就越长，可以理解为服务器已经无法承担如此大的压力，只能排队执行了。<br>类比于一个面包店，正常情况下，一个服务员可以解决店内某一时刻一人结账，如果此时有两人结账，那么其中一人只能等待。此时结账还可控，只是第二位客人结账时间会延长，但如果有十人同时结账，此时只能一个接一个的排队结账了，最后一位客人的结账周期就会非常漫长了。</p><p>linux load avg 可以通过 <code>uptime</code> \ <code>top</code> 等指令查看，也可以通过读取文件 <code>/proc/loadavg</code> 获取相关数值。</p><pre><code class="shell">$ uptime 14:34:03 up 10:43,  4 users,  load average: 0.06, 0.11, 0.09</code></pre><p>load avg 后跟有三个数值，分别以逗号分隔开，这三个数字分别代表了系统近 1 分钟、5 分钟、15 分钟的平均负载情况。</p><p>实时的系统运行情况可以通过 <code>vmstat</code> 查询，获取到更细粒度的系统运行状态。</p><pre><code class="shell"># 以每 1 秒为间隔，连输打印五次$vmstat 1 5procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 4  1      0 2311684 178948 18389776    0    0     3   189   17    9 13  8 79  0  0 1  0      0 2311404 178952 18390256    0    0     0   384 18457 32160  3  3 94  0  0 2  1      0 2312008 178952 18390368    0    0     0   608 18300 31971  5  3 92  1  0 1  0      0 2311052 178952 18390636    0    0     0   636 18108 31634  3  3 94  1  0 3  1      0 2311168 178952 18390784    0    0     0   576 19212 32975  5  3 92  0  0</code></pre><h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><h3 id="通过-CPU-使用率定位"><a href="#通过-CPU-使用率定位" class="headerlink" title="通过 CPU 使用率定位"></a>通过 CPU 使用率定位</h3><p>通过 CPU 的使用率来定位某个进程/线程的运行问题。</p><p><strong>执行方案：</strong></p><p><strong>1. 先定位出 CPU 使用率较高的进程，找到对应的进程 id</strong></p><pre><code class="shell">$top# 进入交互界面后，按 P 使进程按照 CPU 使用率排序</code></pre><p><strong>2. 找到对应进程的使用 CPU 较高的子进程</strong></p><pre><code class="shell">$top -Hp &lt;pid&gt;# &lt;pid&gt; 就是第一步查出来的进程 id</code></pre><p>此时已经能定位到某些 CPU 占用较高的进程</p><p><em>如果是 JVM 项目，那么可以继续向下定位到 JVM 的执行堆栈。</em></p><p><strong>JVM 项目</strong></p><p><strong>3. 将第二步得到的进程 id 转换为十六进制</strong></p><pre><code class="shell">$printf &quot;0x%x\n&quot; &lt;pid&gt;# &lt;pid&gt; 是第二步查出的进程 id</code></pre><p><strong>4. 将第三步得到的十六进制和 jstack 比较找到堆栈</strong></p><pre><code class="shell">$jstack &lt;pid&gt; &gt; jstack.tmp# 打印 JVM 进程堆栈到 jstack.tmp 文件# 后续只需要在文件中搜索第三步的十六进制字符串，即可找到其对应的堆栈</code></pre><p><strong>以上步骤已有脚本实现，可以参考使用。</strong> [^1] 不过在多用户的 linux 中可能会出现使用上的问题，所以基本的排查原理还是要熟知。</p><h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><ul><li>sar 工具</li><li>iostat 工具</li></ul><p>[^1]: <a href="https://github.com/oldratlee/useful-scripts/blob/dev-2.x/docs/java.md#-show-busy-java-threads">查找 CPU 使用最高的 Java 线程</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;load-avg&quot;&gt;&lt;a href=&quot;#load-avg&quot; class=&quot;headerlink&quot; title=&quot;load avg&quot;&gt;&lt;/a&gt;load avg&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://en.</summary>
      
    
    
    
    <category term="Linux" scheme="http://nickchenyx.github.io/categories/Linux/"/>
    
    
    <category term="linux" scheme="http://nickchenyx.github.io/tags/linux/"/>
    
    <category term="运维" scheme="http://nickchenyx.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="问题排查" scheme="http://nickchenyx.github.io/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>Linux 开发运维操作记录</title>
    <link href="http://nickchenyx.github.io/2020/08/17/linux-devops/"/>
    <id>http://nickchenyx.github.io/2020/08/17/linux-devops/</id>
    <published>2020-08-17T05:22:51.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><blockquote><p>此篇文章碎片式积累了 linux 上的相关操作，使用时可以搜索当前页面</p></blockquote><h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><p><strong>压缩日志并删除原始文件</strong></p><pre><code class="shell">#!/bin/bashyesterday=`date -d &#39;1days ago&#39; +%Y_%m_%d`cd $1find . -name &quot;*$yesterday*.log&quot; -type f | xargs -I &#123;&#125; tar -zcvf &#123;&#125;.tar.gz &#123;&#125; --remove-files</code></pre><p>说明加上参数<code>--remove-files</code>，<code>tar</code> 命令可以压缩并删除的源文件</p><p>这样只能删除文件，如果删除源文件夹，可以使用以下方法</p><pre><code class="shell">tar -zcvf aaa/ aaa.tar.gz &amp;&amp; rm -rf aaa</code></pre><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><p><strong>查看进程启动时间</strong></p><pre><code class="shell"># 启动时间ps -eo lstart# 运行多长时间ps -eo etime# 直接查看进程的启动时间ps -eo pid,lstart,etime | grep &lt;pid&gt;</code></pre><p><strong>查看进程系统调用</strong></p><pre><code class="shell"># 通常 -p &lt;pid&gt; 即可# -f 可以跟踪其子进程的系统调用，也就可以跟踪一个多线程服务的所有系统调用了strace -f -p &lt;pid&gt;</code></pre><p><strong>查看进程的内存占用</strong></p><pre><code class="shell"># 查看进程的内存占用情况pmap -x &lt;pid&gt;</code></pre><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><p><strong>查看剩余可用内存</strong></p><pre><code class="shell">free -hfree -m</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;此篇文章碎片式积累了 linux 上的相关操作，使用时可以搜索当前页面&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;文件&quot;&gt;&lt;a href=&quot;#文件&quot; class=&quot;headerlink&quot; title=&quot;文件&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="Linux" scheme="http://nickchenyx.github.io/categories/Linux/"/>
    
    
    <category term="linux" scheme="http://nickchenyx.github.io/tags/linux/"/>
    
    <category term="运维" scheme="http://nickchenyx.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>git 使用手册</title>
    <link href="http://nickchenyx.github.io/2020/08/01/git-usage/"/>
    <id>http://nickchenyx.github.io/2020/08/01/git-usage/</id>
    <published>2020-08-01T02:57:56.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h3 id="git-log-使用"><a href="#git-log-使用" class="headerlink" title="git log 使用"></a>git log 使用</h3><p><strong>git rebase</strong></p><pre><code>---A---B---C---D(master)        \         \---E&#39;---F&#39; (feat)j</code></pre><p>当前开发在 feat 分支，需要合并 master 代码，使用：</p><pre><code class="shell">➜ git rebase -i master</code></pre><p>合并的时候处理好冲突，合并结束后：</p><pre><code>            (master)---A---B---C---D---E&#39;---F&#39;(feat)</code></pre><p>此时如果需要将 master 更新到 feat 处，可以使用：</p><pre><code class="shell">➜ git checkout master➜ git merge --ff feat</code></pre><p>执行完成后：</p><pre><code>---A---B---C---D---E&#39;---F&#39;(feat)                         \                          \(master)</code></pre><p>删除 feat 分支可以使用：</p><pre><code>➜ git branch -d feat</code></pre><p>此时分支链路为：</p><pre><code>---A---B---C---D---E---F(master)</code></pre><p><strong>精简 log 打印</strong></p><pre><code class="shell">git log --online# 01e21e1 (HEAD -&gt; master, origin/master, origin/HEAD) !2 Feature:add lambda support# 55118f9 Feature:add lambda support# 96c6a84 !1 Feat：clean code fragement Merge pull request !1 from 寒沧丶/clean# d52d730 clean:clean code fragment# 0b2ab33 update .gitignore.# d682d2b update README.md.</code></pre><p><strong>查询时间范围内的 log 信息</strong></p><pre><code class="shell"># 只显示2020-08-01到2020-08-08日的提交 git log --after=&quot;2020-08-01&quot; --before=&quot;2020-08-08&quot;# 显示昨天之后的提交git log --after=&quot;yesterday&quot;# 显示这一星期的提交git log --after=&quot;1 week ago&quot;git log --after=&quot;10 day ago&quot;git log --after=&quot;1 month ago&quot;</code></pre><p><strong>在log 中展示变更</strong></p><pre><code class="shell">git log -p# commit 679890d2e3cd7cb53ca586cea72ad1d5abb472e5# Author: tianyaleixiaowu &lt;272551766@qq.com&gt;# Date:   Mon May 11 21:55:34 2020 +0800# #     update QuickStart.md.# # diff --git a/QuickStart.md b/QuickStart.md# index 01c8cc9..0bbc812 100644# --- a/QuickStart.md# +++ b/QuickStart.md# @@ -26,7 +26,7 @@#          &lt;dependency&gt;#             &lt;groupId&gt;com.gitee.jd-platform-opensource&lt;/groupId&gt;#             &lt;artifactId&gt;asyncTool&lt;/artifactId&gt;# -           &lt;version&gt;V1.2-SNAPSHOT&lt;/version&gt;# +           &lt;version&gt;V1.3-SNAPSHOT&lt;/version&gt;^M#         &lt;/dependency&gt;</code></pre><p>*<em>根据提交者过滤 log *</em></p><pre><code class="shell">git log --author=&quot;nickChen&quot;</code></pre><p><strong>根据提交信息检索 log</strong></p><pre><code class="shell">git log --grep=&quot;README&quot;# -i 忽略大小写git log -i --grep=&quot;README&quot;# 正则搜索包含 README 或 changelog 的提交信息git log -i --grep=&quot;README\|changelog&quot;</code></pre><p><strong>查看某个文件的变更log</strong></p><pre><code class="shell"># 查看这几个文件的提交记录，并打印diffgit log -p README.md changelog# 上述情况下，查询包含 fix 信息的提交记录git log -i --grep=&quot;fix&quot; -p README.md changelog</code></pre><p><strong>查看文件内容的变更 log</strong></p><pre><code class="shell"># 查看提交变更中包含 void begin(); 所有 commit log，并打印 log 变更内容# 根据文件内容的提交来查询变更，比较方便定位代码中的一些变化git log -i -S&quot;void begin();&quot; -p</code></pre><p><strong>查看 merge commit log</strong></p><pre><code class="shell">git log --merges</code></pre><p><strong>查看两个分支之间的diff</strong></p><pre><code class="shell"># 查看在 develop 基础上相较于 master 多了哪些 commitgit log master..develop</code></pre><p><strong>自定义 log 的输出格式</strong></p><pre><code class="shell">git log --pretty=format:&quot;%Cred%an - %ar%n %Cblue %h -%Cgreen %s %n&quot;</code></pre><p>具体的格式化方式可以参看<a href="https://www.git-scm.com/docs/git-log?ref=hackernoon.com#_pretty_formats">文档</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h3 id=&quot;git-log-使用&quot;&gt;&lt;a href=&quot;#git-log-使用&quot; class=&quot;headerlink&quot; title=&quot;git log 使用&quot;&gt;&lt;/a&gt;git log 使用&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;git rebase&lt;/stron</summary>
      
    
    
    
    <category term="工具" scheme="http://nickchenyx.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="git" scheme="http://nickchenyx.github.io/tags/git/"/>
    
    <category term="使用手册" scheme="http://nickchenyx.github.io/tags/%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>程序员修炼之道(The Pragmatic Programmer)</title>
    <link href="http://nickchenyx.github.io/2020/07/19/ThePragmaticProgrammer/"/>
    <id>http://nickchenyx.github.io/2020/07/19/ThePragmaticProgrammer/</id>
    <published>2020-07-19T03:20:58.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2 id="从小工到专家-From-Journeyman-to-Master"><a href="#从小工到专家-From-Journeyman-to-Master" class="headerlink" title="从小工到专家(From Journeyman to Master)"></a>从小工到专家(From Journeyman to Master)</h2><p><strong>1&gt; 我的源码让猫吃了</strong><br>对自己的业务负责，在突发状况下能够提供解决方案而不是说“我的源码让猫吃了”。</p><p><strong>2&gt; 软件的熵</strong><br>软件的发展必然会带来更多的无序，在这个过程中要避免“破窗子”出现时，容忍他的存在。要及时修理“破窗子”，反之更多的“破窗子”也就不会在意了，这将加速软件的衰败。（破窗子：低劣的设计、错误决策、糟糕代码…）</p><p><strong>3&gt; 石头汤与青蛙</strong><br>石头汤：做变化的催化剂——一个项目的启动需要由开头的基石，基石的成功会引起各方的加入共同完成这个项目，做这个基石以促成项目更快更好发展。<br>青蛙：记住大背景——在项目过程中要牢牢盯住大背景，要持续关注周围发生的事情，而不仅仅是当前所在做的事情。避免成为温水煮青蛙。</p><p><strong>4&gt; 足够好的软件</strong><br>*<em>&gt; *</em></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;从小工到专家-From-Journeyman-to-Master&quot;&gt;&lt;a href=&quot;#从小工到专家-From-Journeyman-to-Master&quot; class=&quot;headerlink&quot; title=&quot;从小工到专家(From Jou</summary>
      
    
    
    
    <category term="书籍" scheme="http://nickchenyx.github.io/categories/%E4%B9%A6%E7%B1%8D/"/>
    
    
    <category term="book" scheme="http://nickchenyx.github.io/tags/book/"/>
    
    <category term="pragmatic" scheme="http://nickchenyx.github.io/tags/pragmatic/"/>
    
  </entry>
  
  <entry>
    <title>Redis 线上运维操作</title>
    <link href="http://nickchenyx.github.io/2020/05/08/redis-devops/"/>
    <id>http://nickchenyx.github.io/2020/05/08/redis-devops/</id>
    <published>2020-05-08T08:08:14.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h3 id="线上-KEY-批量删除"><a href="#线上-KEY-批量删除" class="headerlink" title="线上 KEY 批量删除"></a>线上 KEY 批量删除</h3><p>Redis 删除特定前缀的 key，需要注意性能影响，比较直观的模糊删除的方式是:</p><pre><code class="shell"># 错误示范，生产环境不可用！redis-cli --raw keys &quot;service:order:*&quot; | xargs redis-cli del</code></pre><p>使用 redis-cli 执行 <code>KEYS</code> 指令模糊匹配对应的 key，再利用管道传递给 redis-cli 执行 <code>DEL</code> 指令。这里的 <code>KEYS</code> 指令是个性能隐患。</p><blockquote><p>实际上阿里云 4G 的 redis 实例上，只有 500 MB 左右的内存占用时，<code>KEYS</code> 指令的 rt 已经达到了 500ms+ 的程度，严重影响了 Redis 的性能。</p></blockquote><blockquote><p>此处 redis-cli 命令最简化了，实际上线上机器应当还有 host/password 等相关信息需要配置在 redis-cli 的参数上</p></blockquote><p>线上不能使用 <code>KEYS</code> 指令应该成为编码过程中必须注意的点，实际也可以禁用 Redis 的 <code>KEYS</code> 指令，避免开发人员误操作。</p><blockquote><p>修改 redis.conf 文件，添加 <code>rename-command KEYS &quot;&quot;</code> 即可，可以理解为重命名某个指令，重命名为空字符串即为禁用</p></blockquote><p><strong>使用 <code>SCAN</code> 指令进行模糊匹配的操作（Redis 2.8 开始支持此指令）</strong></p><p><code>SCAN</code> 指令的具体用法不在此处描述，此处实际要利用的是 <code>SCAN</code> 指令的特性进行模糊匹配要删除的 key。</p><pre><code class="bash">redis-cli --scan --pattern &quot;service:order:*&quot; | xargs redis-cli del</code></pre><p><code>--scan</code> 使用的就是 <code>SCAN</code> 指令的特性进行了 key 的模糊匹配，对比 <code>KEYS</code> 指令这个操作不会阻塞 Redis 操作，对线上业务没有影响。</p><p>需要注意上述操作模糊删除 <code>string</code> 类型的 Redis 键时时间复杂度为 O(1)，但是对于其他数据结构时间可能不一样了。比如 <code>set</code> 数据结构，如果直接使用 <code>DEL</code> 指令删除这个 <code>set</code> 数据结构的 key，他的时间复杂度并不是 O(1)，而是 O(M)，M 为数据结构中元素的数量。也就是意味着如果这个数据集合过大，这个 <code>DEL</code> 指令的执行实际上也有性能风险（此处可看官方文档中的 <a href="https://redis.io/commands/del"><code>DEL</code></a> 时间复杂度描述）。</p><p>面对除了 <code>string</code> 类型的其他数据结构，Redis 有对应的 <code>HSCAN</code>、<code>SSCAN</code>、<code>ZSCAN</code> 指令可以遍历其元素，利用这一特性可以整理出以下的批量删除脚本。</p><p><strong>批量删除 <code>set</code> 数据结构中的数据</strong></p><pre><code class="python">import redisdef del_big_set_key(key_name):    r = redis.StrictRedis(host=&#39;localhost&#39;, port=6379)    # count表示每次删除的元素数量，这里每次删除300元素    for key in r.sscan_iter(name=key_name, count=300):        r.srem(key_name, key)del_big_set_key(&#39;ops-coffee&#39;)</code></pre><p><strong>批量删除 <code>hash</code> 数据结构中的数据</strong></p><pre><code class="python">import redisdef del_big_hash_key(key_name):    r = redis.StrictRedis(host=&#39;localhost&#39;, port=6379)    # hscan_iter获取出来的结果是个元祖，下边hdel删除用key[0]取到key    for key in r.hscan_iter(name=key_name, count=300):        r.hdel(key_name, key[0])del_big_hash_key(&#39;ops-coffee&#39;)</code></pre><p><strong>批量删除 <code>zset</code> 数据结构中的数据</strong></p><pre><code class="python">import redisdef del_big_sort_key(key_name):    r = redis.StrictRedis(host=&#39;localhost&#39;, port=6379)    while r.zcard(key_name) &gt; 0:        # 判断集合中是否有元素，如有有则删除排行0-99的元素        r.zremrangebyrank(key_name, 0, 99)del_big_sort_key(&#39;ops-coffee&#39;)</code></pre><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>咖啡运维吧：<a href="https://ops-coffee.cn/s/x48wmx_k55hmpfzl0tybyq">Redis删除特定前缀key的优雅实现</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h3 id=&quot;线上-KEY-批量删除&quot;&gt;&lt;a href=&quot;#线上-KEY-批量删除&quot; class=&quot;headerlink&quot; title=&quot;线上 KEY 批量删除&quot;&gt;&lt;/a&gt;线上 KEY 批量删除&lt;/h3&gt;&lt;p&gt;Redis 删除特定前缀的 key，需要注</summary>
      
    
    
    
    <category term="数据库" scheme="http://nickchenyx.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="运维" scheme="http://nickchenyx.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="Redis" scheme="http://nickchenyx.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 实现 (待补全)</title>
    <link href="http://nickchenyx.github.io/2019/03/27/redis-implements/"/>
    <id>http://nickchenyx.github.io/2019/03/27/redis-implements/</id>
    <published>2019-03-27T06:56:39.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-设计与实现"><a href="#Redis-设计与实现" class="headerlink" title="Redis 设计与实现"></a>Redis 设计与实现</h1><h2 id="Redis-的-String-设计"><a href="#Redis-的-String-设计" class="headerlink" title="Redis 的 String 设计"></a>Redis 的 String 设计</h2><blockquote><p>redis 对于 String 类型有自己的实现, 这个实现简称 SDS (simple dynamic string).</p></blockquote><p>SDS 的优势：<br>    - 安全性、效率、功能方面的需求<br>        O(1)的获取字符串长度的效率，根据len字段<br>        杜绝缓冲区溢出、根据free字段判断是否扩容</p><pre><code>- 内存预分配：        len小于1M，修改之后的len的长度 = free长度        大于1M，直接free 1M- 惰性释放：        不返还 free 的区域= = 以便下次使用- 二进制安全：        \0 作为分隔符时，因为有len判断字符串长度，不会出现问题    兼容部分C字符串函数</code></pre><h2 id="Redis-的链表设计"><a href="#Redis-的链表设计" class="headerlink" title="Redis 的链表设计"></a>Redis 的链表设计</h2><p>链表：用于列表键、pub/sub、慢查询、监视器<br>    - 双端：获取前后节点复杂度都O(1)</p><pre><code>- 无环：前后NULL节点- 带head tail- 表长len- 多态 void* 保存节点值</code></pre><h2 id="Redis-的字典实现"><a href="#Redis-的字典实现" class="headerlink" title="Redis 的字典实现"></a>Redis 的字典实现</h2><p>字典：SET 和 HSET<br>    - 使用哈希表错位底层实现，是redis 是数据库的存储方式<br>    - 使用dictht 作为哈希表实现，封装成 dict，内有长度为2的dictht数组，<br>        用来做扩容，标记位为-1时表示不在rehash<br>        dict ｛<br>            dictht[2]<br>            dictType 实现多态的函数，复制对比删除等<br>            rehashindex -1表示不在rehash<br>        ｝<br>        扩展 ht[1]大小为 第一次大于ht[0].used*2 的 2^n<br>        收缩 。。。。。。。。。大于ht[0].used 的 2^n<br>    - 渐进式哈希：每次插入删除查找更新都rehash一次</p><h2 id="Redis-的跳表实现"><a href="#Redis-的跳表实现" class="headerlink" title="Redis 的跳表实现"></a>Redis 的跳表实现</h2><p>跳表：<br>    - 实现有序集数据<br>    - 随机化数据结构、它的查找添加删除都可以在对数期望时间下完成</p><h2 id="Redis-的压缩列表实现"><a href="#Redis-的压缩列表实现" class="headerlink" title="Redis 的压缩列表实现"></a>Redis 的压缩列表实现</h2><p>压缩列表：<br>    - ziplist结构：<br>            header - entries - end<br>         bytes-tail-len<br>    - entry结构：<br>            prelen - encoding - len - content</p><h2 id="Redis-的引用对象实现"><a href="#Redis-的引用对象实现" class="headerlink" title="Redis 的引用对象实现"></a>Redis 的引用对象实现</h2><p>redisObject 结构：<br>    - key 对应的是一个 redisObject 结构，用来多态操作<br>        redisObject {<br>            type.<br>            encoding.   type 和 encoding 定位底层数据结构<br>            *ptr<br>        }<br>        引用计数回收</p><ul><li><p>哈希表默认由压缩列表实现：当某个key/value长度大于64 </p><pre><code>                  或者 entries 的个数大于 512                   会转变成字典实现</code></pre></li><li><p>列表默认也由压缩列表实现：同上；会转变为双端链表</p></li><li><p>阻塞：维持一个server[i]-&gt;block_keys列表，key为造成阻塞的key，value为客户端链接<br>  readyList 用来保存即将离开block队列</p></li><li><p>事务：WATCH MULTI DISCARD EXEC</p></li><li><p>慢日志查询：设置时间和保存数量</p><pre><code>   SLOW GET 查看</code></pre></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis-设计与实现&quot;&gt;&lt;a href=&quot;#Redis-设计与实现&quot; class=&quot;headerlink&quot; title=&quot;Redis 设计与实现&quot;&gt;&lt;/a&gt;Redis 设计与实现&lt;/h1&gt;&lt;h2 id=&quot;Redis-的-String-设计&quot;&gt;&lt;a href=&quot;#</summary>
      
    
    
    
    <category term="数据库" scheme="http://nickchenyx.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="Cache" scheme="http://nickchenyx.github.io/tags/Cache/"/>
    
    <category term="缓存" scheme="http://nickchenyx.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
    <category term="Redis" scheme="http://nickchenyx.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Screen 使用指南</title>
    <link href="http://nickchenyx.github.io/2018/05/09/screen-manual/"/>
    <id>http://nickchenyx.github.io/2018/05/09/screen-manual/</id>
    <published>2018-05-09T13:48:29.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Screen-使用流程"><a href="#Screen-使用流程" class="headerlink" title="Screen 使用流程"></a>Screen 使用流程</h1><p>参考资料：</p><ul><li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-screen/index.html">https://www.ibm.com/developerworks/cn/linux/l-cn-screen/index.html</a></li><li><a href="http://man.linuxde.net/screen">http://man.linuxde.net/screen</a></li></ul><p>Screen 是管理会话的一个工具，能够持有多个会话并维持，方便切换，真切的提高工作效率。</p><h2 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h2><p><strong>1&gt; 创建会话</strong> </p><p>直接键入 <code>screen</code> 就可以开启一个新的会话窗口：</p><pre><code class="shell">➜ screen# 执行之后立刻进入一个新的会话</code></pre><p>也可以在后面跟指令，可以直接在新会话中执行这条指令：</p><pre><code class="shell">➜ screen vim new.txt# 这里如果使用 :q 推出 vim 的话，也会直接退出当前的会话</code></pre><p>在 <code>screen</code> 管理的会话中想要创建新的会话可以使用 <code>C-a c</code>。</p><blockquote><p>这里的 <code>C-a</code> 指的是 <code>Ctrl + a</code>，是 <code>screen</code> 的命令字符（command character）。</p></blockquote><p><strong>2&gt; 管理会话</strong></p><p>Q: 创建了多个 screen 会话之后，如何实现会话之间的跳转？</p><p>A: 使用 <code>C-a 0..9.</code>  在 0 ～ 9 会话之间切换，  <code>C-a n</code>  切换到下一个会话，<code>C-a p</code> 切换到上一个会话。</p><p>快速回到上一个会话：使用了 <code>C-a 0</code> 进入了会话 0，再使用会话 <code>C-a 3</code> 进入了会话 3，可以直接使用 <code>C-a C-a</code> 返回上一个会话——即会话 0。</p><p>Q: 如何看当前新建了哪些会话？</p><p>A: 使用 <code>C-a w</code> 显示所有的窗口列表。</p><pre><code class="shell">➜  0- /  1* /  2 /  3 /  4 /# * 号表示的是当前会话</code></pre><p>Q: 会话都是 0～9 不方便区分会话任务，如何处理？</p><p>A: 使用 <code>C-a A</code> 给会话起别名，这样在使用  <code>C-a w</code> 指令后可以看到所有会话的别名用来区分任务。</p><pre><code class="shell">➜ 0 /vim  1 /vim1  2- /upload  3* /do  4 /# 可以看到 0 和 1 在执行 vim，2 在执行一个上传任务，3 在做些别的事儿，4 还没有起别名</code></pre><p><strong>3&gt; 挂起|重连会话</strong></p><p>可以使用 <code>C-a d</code> 用来挂起 <code>screen</code> 会话，这样就可以回到原来的终端了：</p><pre><code class="shell">[detached] # 挂起 screen 会话之后打印的 echo➜  / # 已经回到原来的终端</code></pre><p>使用 <code>screen -ls</code> 可以看到这个被挂起的会话：</p><pre><code class="shell">➜  / screen -lsThere is a screen on:    3187.ttys002.lzdeMBP    (Detached) # 这就是被挂起的会话1 Socket in /var/folders/mh/zj230g0x2996t8qvszyj3qy80000gn/T/.screen.</code></pre><p>可以使用 <code>screen -r &lt;session pid&gt;</code> 重连到该会话：</p><pre><code class="shell">➜  / screen -r 3187</code></pre><p>这样就能重新进入 <code>screen</code> 会话了。</p><p>创建了多个会话之后，有的会话已经完成了它的职责，这时候需要关闭它了。</p><p>使用 <code>C-a k</code> 可以关闭当前会话。</p><p>其他常用指令：</p><table><thead><tr><th>-c file</th><th>使用配置文件file，而不使用默认的$HOME/.screenrc</th></tr></thead><tbody><tr><td>-d/-D [pid.tty.host]</td><td>不开启新的screen会话，而是断开其他正在运行的screen会话</td></tr><tr><td>-h num</td><td>指定历史回滚缓冲区大小为num行</td></tr><tr><td>-list/-ls</td><td>列出现有screen会话，格式为pid.tty.host</td></tr><tr><td>-d -m</td><td>启动一个开始就处于断开模式的会话</td></tr><tr><td>-r sessionowner/ [pid.tty.host]</td><td>重新连接一个断开的会话。多用户模式下连接到其他用户screen会话需要指定sessionowner，需要setuid-root权限</td></tr><tr><td>-S sessionname</td><td>创建screen会话时为会话指定一个名字</td></tr><tr><td>-v</td><td>显示screen版本信息</td></tr><tr><td>-wipe [match]</td><td>同-list，但删掉那些无法连接的会话</td></tr></tbody></table><p>-d –m 选项是一对很有意思的搭档。他们启动一个开始就处于断开模式的会话。</p><p>你可以在随后需要的时候连接上该会话。有时候这是一个很有用的功能，比如我们观察日志文件。</p><p>该选项一个更常用的搭配是：-dmS sessionname 启动一个初始状态断开的 <code>screen</code> 会话：</p><pre><code class="shell">➜ / screen -dmS xxxLog tail -n 10 -f zk.log# 这里就开启了一个观察日志的会话# 下面只需要执行程序，然后重连到这个会话就好了➜ / screen -r xxxLog# 连接到打印日志的会话</code></pre><p><strong>4&gt; 分屏使用</strong></p><p>充分利用大屏优势：</p><ul><li>使用 <code>C-a S</code> 可以上下分屏，<code>C-a |</code> 可以水平分屏(这个要高版本才有了)</li><li>使用 <code>C-a Tab</code> 可以切换到另一个屏幕</li><li>使用 <code>C-a X</code> 可以取消当前分屏</li></ul><h2 id="管理-Screen"><a href="#管理-Screen" class="headerlink" title="管理 Screen"></a>管理 Screen</h2><p>同大多数UNIX程序一样，GNU Screen提供了丰富强大的定制功能。你可以在Screen的默认两级配置文件 <code>/etc/screenrc</code> 和 <code>$HOME/.screenrc</code> 中指定更多，例如设定screen选项，定制绑定键，设定screen会话自启动窗口，启用多用户模式，定制用户访问权限控制等等。</p><p><strong>配置 ～/.screenrc</strong></p><pre><code class="shell"># Set default encoding using utf8defutf8 on## 解决中文乱码,这个要按需配置defencoding utf8encoding gbk utf8#兼容shell 使得.bashrc .profile /etc/profile等里面的别名等设置生效shell -$SHELL#set the startup messagestartup_message offterm linux## 解决无法滚动termcapinfo xterm|xterms|xs ti@:te=\E[2J# 屏幕缓冲区行数defscrollback 10000# 下标签设置hardstatus oncaption always &quot;%&#123;= kw&#125;%-w%&#123;= kG&#125;%&#123;+b&#125;[%n %t]%&#123;-b&#125;%&#123;= kw&#125;%+w %=%d %M %0c %&#123;g&#125;%H%&#123;-&#125;&quot;#关闭闪屏vbell off</code></pre><h1 id="TODO…"><a href="#TODO…" class="headerlink" title="TODO…"></a>TODO…</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Screen-使用流程&quot;&gt;&lt;a href=&quot;#Screen-使用流程&quot; class=&quot;headerlink&quot; title=&quot;Screen 使用流程&quot;&gt;&lt;/a&gt;Screen 使用流程&lt;/h1&gt;&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:</summary>
      
    
    
    
    <category term="Linux" scheme="http://nickchenyx.github.io/categories/Linux/"/>
    
    
    <category term="运维" scheme="http://nickchenyx.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="Linux" scheme="http://nickchenyx.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 总集</title>
    <link href="http://nickchenyx.github.io/2018/04/18/mysql-cmd/"/>
    <id>http://nickchenyx.github.io/2018/04/18/mysql-cmd/</id>
    <published>2018-04-18T03:19:10.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<p><code>show status</code> 或 <code>show session status</code></p><p>⬆查看当前MySQL服务器连接的会话状态变量信息；</p><p><code>show global status</code></p><p>⬆查看全局状态变量；</p><p><code>flush status</code></p><p>⬆初始化当前会话状态变量</p><p><code>show variables</code></p><p>⬆查看全局系统变量、会话系统变量和静态变量等；</p><hr><h3 id="MySQL-缓存："><a href="#MySQL-缓存：" class="headerlink" title="MySQL 缓存："></a>MySQL 缓存：</h3><p><strong>按缓存读写功能不同划分</strong></p><ul><li>Cache 缓存 （加速读）</li><li>Buffer 缓存 （缓冲写）</li></ul><p><strong>按生存周期长短划分</strong></p><ul><li>全局缓存 例如二进制日志 binlog_cache_size</li><li>会话缓存 例如结果集缓存 net_buffer_size</li><li>临时缓存 例如select语句中包含的派生表生成的内存临时表</li></ul><p><strong>按存储引擎实现划分</strong></p><ul><li>MySQL 缓存</li><li>MyISAM 缓存</li><li>InnoDB 缓存</li></ul><hr><h3 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h3><p><code>show variables like &#39;%timeout%&#39;</code></p><p>⬆查看超时相关变量配置</p><p><strong>连接超时</strong></p><ul><li>connect_timeout 建立连接超时</li><li>wait_timeout 保持睡眠状态太长，超时</li><li>interactive_timeout 交互模式下（cmd）保持睡眠状态太长，超时</li><li>net_write_timeout 默认60秒 写超时</li><li>net_read_timeout 默认30秒 读超时</li></ul><p><strong>InnoDB 锁等待超时</strong></p><ul><li>innodb_lock_wait_timeout 默认50秒 设置行级锁锁等待时间，超时触发导致行级锁锁等待的SQL语句回滚（若希望整个事务回滚，启动MySQL时开启 innodb_rollback_on_timeout 参数）</li><li>innodb_rollback_on_timeout 默认OFF 回滚上一条导致行级锁锁等待的SQL语句， 设置为ON则回滚整个事务</li></ul><p><strong>元数据锁超时 metadata locks</strong></p><ul><li>lock_wait_timeout 默认值1年 31536000 取值范围[1, 31536000]</li></ul><p><strong>复制连接超时</strong></p><ul><li>slave_net_timeout 默认3600秒 MySQL主从复制时，从拉取主二进制日志失败后，等待该设置的时间后，再重连主获取数据。 设置为30秒，减少网络问题导致的数据同步延迟。</li></ul><p><strong>MyISAM 表的延迟插入超时</strong></p><ul><li>delayed_insert_timeout</li></ul><hr><h3 id="MySQL-连接的优化"><a href="#MySQL-连接的优化" class="headerlink" title="MySQL 连接的优化"></a>MySQL 连接的优化</h3><p><strong>连接参数</strong></p><p><code>show variables like &#39;%connect%&#39;</code></p><p>⬆查询MySQL服务的连接参数信息</p><ul><li>max_connections 设置最大的并发连接数，拥有SUPER权限的用户可以在连接数达到最大时依然能建立链接。</li><li>max_user_connections 设置指定的MySQL账号的最大并发连接数，设置为0表示不限制</li><li>max_connect_errors 某主机连接到MySQL服务器失败次数过多，超过该值，服务器会拒绝该主机的连接，除非执行 flush hosts</li><li>init_connect 客户机连接服务器时，会先执行 init_connect 参数内设置的SQL语句。SUPER权限的用户连接不会执行这些SQL语句</li></ul><p><strong>连接状态</strong></p><p><code>show status like &#39;%connections%&#39;</code></p><p>⬆查看当前实例连接MySQL服务的状态信息</p><ul><li>Connections Mysq服务从启动到现在尝试连接的请求数（包括不能成功建立的连接请求）</li><li>max_used_connections 表示MySQL服务从启动到现在，同一时刻并行连接的最大值。如果 max_used_connections 和 max_connections 相同， 则说明 max_connections 设置过低或者服务器负载上限。</li><li>connection_errors_max_connections 由于MySQL服务器已经达到 max_connections 的上限，连接被拒绝的次数。如果该值过大，则说明 max_connections 设置过低或者服务器负载上限。</li></ul><p><strong>连接线程参数</strong></p><p><code>show variables like &#39;thread%&#39;</code></p><p>⬆查看MySQL连接线程参数信息</p><ul><li>thread_cache_size 表示当前可用的MySQL连接池大小</li><li>thread_concurrency 针对Solaris系统设置为CPU核心数的2倍</li><li>thread_handling 默认为 one-thread-per-connection，值为 no-threads 只能提供一个连接线程</li><li>thread_stack 默认 192KB， 配置连接线程分配的内存大小用于保存每个连接线程的信息</li></ul><p><strong>连接状态信息</strong></p><p><code>show status like &#39;Thread%&#39;</code></p><p>⬆查看连接线程的状态信息</p><ul><li>Threads_cached 当前线程池的线程数</li><li>Threads_connected 当前连接数</li><li>Threads_created 连接线程创建数，该值过大会扩充连接池大小</li><li>Threads_running 不在睡眠状态的连接线程数量</li></ul><p>连接池的连接命中率 = （Connections - Threads_created）/ connections * 100%</p><p>该值较低时，需要增加 thread_cache_size。</p><p><strong>连接请求堆栈</strong></p><p><code>show variables like &#39;back_log&#39;</code></p><p>⬆查询堆栈中的连接请求（因连接数过大而被塞入）</p><p><strong>连接异常</strong></p><p><code>show status like &#39;Aborted%&#39;</code></p><p>⬆查看连接异常的状态信息</p><ul><li>Aborted_clients MySQL客户机被异常关闭的次数。例如发送的SQL语句过长或者select语句执行结果太大，超过 max_allowed_packet 参数值，或者 wait_timeout、 interactive_timeout （ max_allowed_packet 默认 1M）</li><li>Aborted_connects 试图连接到MySQL服务器而失败的连接次数，该次数过大可能有网络问题。错误的账户名密码或者无效的数据库都会使得该值递增。</li></ul><p><strong>其他</strong></p><p><code>show status like &#39;Slow%&#39;</code></p><p>⬆查看其他链接状态</p><ul><li>Slow_launch_threads 记录创建时间超过 slow_launch_time 的线程数，如果该值过大，可能是服务器过载。 （默认情况下， slow_launch_time 为 2秒）</li></ul><p><code>show status like &#39;Connection_error%&#39;</code></p><p>⬆查看连接错误的状态统计信息</p><hr><h3 id="缓存的优化"><a href="#缓存的优化" class="headerlink" title="缓存的优化"></a>缓存的优化</h3><p><code>show variables like &#39;host_cache_size&#39;</code></p><p>⬆查询主机名缓存大小</p><p><code>show variables like &#39;stored_program_cache&#39;</code></p><p>⬆查看MySQL为每个会话提供的存储程序缓存个数上限</p><p><code>show variables like &#39;innodb_ft_cache_size&#39;</code></p><p>⬆查询InnoDB 全文索引缓存的大小</p><p><strong>查询缓存 Query Cache</strong></p><p><code>show variables like &#39;%query_cache%&#39;</code></p><p>⬆查询有关查询缓存的参数设置</p><ul><li>have_query_cache 是否支持查询缓存 YES NO</li><li>query_cache_type 0（OFF） 关闭，1（ON）先到查询缓存中查找，除非</li><li>select 语句中包含 sql_no_cache， 2（DEMOND）不使用查询缓存，除非 select 语句中包含 sql_cache</li><li>query_cache_size 查询缓存的大小</li><li>query_cache_limit 如果 select 语句的结果集大小超过了该值，将不会被添加进查询缓存</li><li>query_cache_min_res_unit 查询缓存是以块为单位分配内存空间，结果集大于该值就会多申请一块，如此反复。合适的值不仅可以减少内存分配操作的次数，还可以减少内存碎片</li><li>query_cache_wlock_invalidate 用于设置行级排他锁与查询缓存之间的关系，默认 0 （false），表示施加行级排他锁时，该表的所有查询缓存依然有效。如果设置为1（true），表示施加行级排他锁时，该表的所有查询缓存将失效。</li></ul><p><strong>查询缓存的命中率</strong></p><p><code>set global query_cache_size = 102760448</code></p><p>⬆开启缓存查询，将其内存大小设置为98M</p><p><code>show status like &#39;Qcache%&#39;</code></p><p>⬆获取当前实例的查询缓存状态，从而可以计算出当前缓存查询的命中率，继而确定 query_cache_size 的设置是否合理</p><ul><li>Qcache_free_memory 当前可用内存</li><li>Qcache_lowmen_prunes 因查询缓存已满而溢出、删除的查询结果个数。该值过大表示需要增加查询缓存大小</li><li>Qcache_hits 使用查询缓存的次数，若该值过小，则考虑是否应该开启查询缓存</li><li>Qcache_total_blocks 查询缓存的总块数</li><li>Qcache_free_blocks 处于空闲的块数（碎片数量）如果该值较大，意味着查询缓存中碎片较多，表明查询结果集比较小，此时可以减少 query_cache_min_res_unit。使用 flush query cache 对碎片进行整理。（reset query cache 会移除查询缓存中的结果集）</li><li>Qcache_inserts 表示此前总共缓存过多少条 select语句的结果集</li><li>Qcache_not_cached 表示没有进入查询缓存的 select语句的个数</li><li>Qcache_queries_in_cache 表示查询缓存中缓存中多少条 select 语句的结果集</li></ul><p><strong>结果集缓存</strong></p><p>select 语句的结果集会暂存在结果集缓存中，结果集缓存的初始大小由 net_buffer_size 定义（默认16KB），如果 select语句的结果集大小超过初始大小，则会自动扩容，但不会超过 max_allowed_packet 的参数值。select 语句执行成功后，结果集缓存空间会“瘦身”到初始大小。</p><p><strong>优化表结构</strong></p><ul><li>尽量将字段定义为 NOT NULL</li><li>考虑使用 enum、 set等复合数据类型</li><li>尽量不存文件、视频等二进制数据</li><li>数值型字段的比较比字符串效率高很多</li></ul><hr><h3 id="SQL语句优化"><a href="#SQL语句优化" class="headerlink" title="SQL语句优化"></a>SQL语句优化</h3><p><strong>了解 SQL 的执行频率</strong></p><p><code>show status like &#39;queries&#39;</code></p><p>⬆执行的 SQL 语句的数量，不统计 com_ping、com_statistics</p><p><code>show global status like &#39;Com_%&#39;</code></p><p>⬆查看MySQL服务执行各种SQL语句的数量</p><ul><li>com_select</li><li>com_insert 批量插入只记一次</li><li>com_update</li><li>com_delete</li></ul><p>可以通过上面的信息了解当前应用偏向于 OLTP 还是 OLAP。</p><ul><li>com_commit</li><li>com_rollback</li></ul><p>可以通过上面信息，了解到rollback从而推断程序中存在某些问题。</p><p><strong>数据处理状态信息</strong></p><p><code>show global status like &#39;handler%&#39;</code></p><p>⬆执行次数查询</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;show status&lt;/code&gt; 或 &lt;code&gt;show session status&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;⬆查看当前MySQL服务器连接的会话状态变量信息；&lt;/p&gt;
&lt;p&gt;&lt;code&gt;show global status&lt;/code&gt;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="数据库" scheme="http://nickchenyx.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="http://nickchenyx.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>JDK1.7 ConcurrentHashMap 解析</title>
    <link href="http://nickchenyx.github.io/2018/04/17/jdk1-7-concurrenthashmap-summary/"/>
    <id>http://nickchenyx.github.io/2018/04/17/jdk1-7-concurrenthashmap-summary/</id>
    <published>2018-04-17T08:04:46.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>力求简单而明确地直指 JDK1.7 ConcurrentHashMap 的设计要点。</p></blockquote><h2 id="线程安全之-ConcurrentHashMap"><a href="#线程安全之-ConcurrentHashMap" class="headerlink" title="线程安全之 ConcurrentHashMap"></a>线程安全之 ConcurrentHashMap</h2><p>在 JDK 中，有 <code>java.util.concurrent</code>包，里面存有这一些线程安全的集合类。其中应用最多的就是 <code>ConcurrentHashMap</code>，这是一个线程安全的 <code>HashMap</code>，不同的 JDK 版本可能使用了不同的技巧来保证这个线程安全的特性。这里我讨论的是 JDK1.7 版本的线程安全设计。</p><p>JDK7 采用了分段锁的方式来保证 <code>ConcurrentHashMap</code> 的线程安全，分段锁的工作原理是：</p><p>在 <code>HashMap</code> 下需要完成线程安全可以使用 <code>Collections.synchronizedMap</code> 构造一个线程安全的 HashMap，他的原理就是利用 <code>synchronized</code> 关键字对基本上所有的方法进行上锁，是一种非常粗暴的解决方案。可想而知的是低性能换来的线程安全。</p><p>而 <code>ConcurrentHashMap</code> 下有多个 <code>Segment</code>(默认 16 个), <code>Segment</code> 下是一个 <code>HashTable</code> 用来存 key-value。 <code>Segment</code> 是继承 <code>ReentrantLock</code>，可以直接享有相关的锁方法。一个数据存入 <code>ConcurrentHashMap</code> 需要先进行一次 hash 来确定他是在哪个 <code>Segment</code> 下，再对该 <code>Segment</code> 上锁写数据。可以看到这一点已经比前者的实现高明了。</p><h2 id="ConcurrentHashMap-的性能优化"><a href="#ConcurrentHashMap-的性能优化" class="headerlink" title="ConcurrentHashMap 的性能优化"></a>ConcurrentHashMap 的性能优化</h2><p>上一节中提到了 <code>put</code> 操作会对 <code>Segment</code> 上锁，事实上这里 JDK7 还有所优化，调用 <code>put</code> 方法会先尝试获取锁，<code>tryLock()</code> 这个是 <code>ReentrantLock</code> 的方法，获取不到会继续去尝试 <code>scanAndLockForPut()</code>，这个方法里会不停的 tryLock()，这里会涉及到 <code>MAX_SCAN_RETRIES</code> 次尝试 <code>tryLock()</code>，超过次数了会直接 <code>lock()</code> 获取锁。在操作最后会在 <code>try...finally</code> 里 <code>unlock()</code> 释放锁。</p><pre><code class="java">static final int MAX_SCAN_RETRIES =            Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1;</code></pre><p>还有 <code>size()</code> 方法获取 <code>ConcurrentHashMap</code> 的大小时，会有一系列的操作来保证得到准确的 size。</p><p>获取 size 大小是一个无限循环，每次循环会先自增一次 <code>retries</code>，只有 <code>retries == RETRIES_BEFORE_LOCK(=2)</code> 时才会将所有的 <code>Segment</code> 都上锁再计算。这里有个 trick，会记录上一次的 <code>Segment</code> 的 modCount 总值，在下一次计算时会比较，如果不相等，那就是再来一次了。这里利用了 map 中 modCount 机制。</p><pre><code class="java">for (;;) &#123;    // 先尝试直接获取 size 大小，这里有计算一个 modCount的数值，会和上次（last）作比较，如果一样的话，说明map没有做增删操作啥的，就是正确的了    // 如果尝试的次数超过了 RETRIES_BEFORE_LOCK， 就直接去锁 segment 再计数    if (retries++ == RETRIES_BEFORE_LOCK) &#123;        for (int j = 0; j &lt; segments.length; ++j)            ensureSegment(j).lock(); // force creation    &#125;    sum = 0L;    size = 0;    overflow = false;    for (int j = 0; j &lt; segments.length; ++j) &#123;        Segment&lt;K,V&gt; seg = segmentAt(segments, j);        if (seg != null) &#123;            sum += seg.modCount;            int c = seg.count;            if (c &lt; 0 || (size += c) &lt; 0)                overflow = true;        &#125;    &#125;    if (sum == last)        break;    last = sum;&#125;</code></pre><p>至于其他的方法，涉及到的锁步骤无非也就上面的重复了，就不多谈了。在此留笔，方便日后再记。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;力求简单而明确地直指 JDK1.7 ConcurrentHashMap 的设计要点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;线程安全之-ConcurrentHashMap&quot;&gt;&lt;a href=&quot;#线程安全之-ConcurrentHash</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Java" scheme="http://nickchenyx.github.io/tags/Java/"/>
    
    <category term="JDK" scheme="http://nickchenyx.github.io/tags/JDK/"/>
    
    <category term="源码" scheme="http://nickchenyx.github.io/tags/%E6%BA%90%E7%A0%81/"/>
    
    <category term="Map" scheme="http://nickchenyx.github.io/tags/Map/"/>
    
  </entry>
  
  <entry>
    <title>JSONP 详解</title>
    <link href="http://nickchenyx.github.io/2018/04/17/jsonp-essentials/"/>
    <id>http://nickchenyx.github.io/2018/04/17/jsonp-essentials/</id>
    <published>2018-04-17T08:04:24.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>简单直白的解释 JSONP 的由来及实现原理</p></blockquote><h2 id="JSONP-详解，不信你听不懂"><a href="#JSONP-详解，不信你听不懂" class="headerlink" title="JSONP 详解，不信你听不懂"></a>JSONP 详解，不信你听不懂</h2><p>对于一样技术，先了解其发展的背景十分重要。因为了解了背景，才能明白他为何要如此设计，能解决什么问题。</p><p>原理有点枯燥，我就挑口语化的来说，你能听懂就行。对术语有兴趣的可以继续谷歌下去。</p><blockquote><p>JavaScript 是一种在 Web 开发中经常使用的前端动态脚本技术。在 JavaScript 中，有一个很重要的安全性限制，被称为 <strong>Same-Origin Policy(同源策略)</strong>。</p></blockquote><blockquote><p>由于同源策略的限制，XmlHttpRequest (which 是 Ajax 实现的方式) 只允许请求当前源（域名、协议、端口）的资源。为了实现跨域请求，可以通过 script 标签实现跨域请求，然后在服务端输出 JSON 数据并执行回调函数，从而解决了跨域的数据请求。<br>利用在页面中创建 <code>&lt;script&gt;</code> 节点的方法向不同域提交 HTTP 请求的方法称为 JSONP，这项技术可以解决跨域提交 Ajax 请求的问题。</p></blockquote><p>也就是出现 JSONP 是为了在同源策略所保证的安全的前提下，绕个弯突破限制获取资源。</p><p>上文说到是利用在页面中创建 <code>&lt;script&gt;</code> 节点，修改 script 节点的 src 属性到目标地址来获取资源，这里就有了 script 标签的局限性 —— script 标签仅支持 GET 请求方式。</p><p><strong>这就是 JSONP 只能是 GET 请求的前因后果。</strong></p><h2 id="JSONP-实现细节"><a href="#JSONP-实现细节" class="headerlink" title="JSONP 实现细节"></a>JSONP 实现细节</h2><p>使用 script 标签，改变 src 属性为目标地址，服务器返回的就是一个文本 (文本内是一个函数)，这个函数作为 js 被执行。</p><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><p><strong>生成的 script：</strong></p><pre><code class="html">// 这是一个由 JSONP 生成的 script 标签// 他请求了一个 user 对象// 注意这里的 *callback=JSONP_CB* 这里定义了一个回调函数的名称，通常在使用 jQ 的时候，可以自定义回调函数名或者不定义由 jQ 自动生成。// 这个函数名将会被后端使用，包裹着数据传回。&lt;script src=&quot;http://localhost:1111/user/1?callback=JSONP_CB&quot;&gt;&lt;/script&gt;</code></pre><p><strong>后端代码：</strong></p><pre><code class="java">// 返回 user 对象， 通常情况下我们只需要返回 json体// 而 JSONP 则会使用回调函数名包裹着数据返回，这也就是一个 js 语法， 等于是调用了一次 JSONP_CB 函数。return &quot;JSONP_CB(&#123;&#39;id&#39;: 1, &#39;name&#39;:&#39;nickChen&#39;&#125;)&quot;</code></pre><p><strong>这里就是回调函数使用的关键了：</strong></p><pre><code class="javascript">// 服务器返回的 JSONP_CB(&#123;&#39;id&#39;: 1, &#39;name&#39;:&#39;nickChen&#39;&#125;) 因为在 script 标签下，作为一个 js 代码运行了// 然后就可以看到巧妙地利用了回调函数取回了数据并执行你的方法来处理数据、// 将 JSONP_CB 注册到成为一个函数window[callbackName] = function(data)&#123; // 关键了，调用你的方法来处理数据 callback(data); // 清场 window.document.body.removeChild(scriptElem);&#125;;</code></pre><h3 id="后续测试"><a href="#后续测试" class="headerlink" title="后续测试"></a>后续测试</h3><p>script, img, iframe, link 四个标签都可以请求到跨域资源，其中 link 也可以完成 script标签实现的 JSONP 功能，即可以调起回调函数。 img 不能处理文本内容，但是可以监听是否响应。iframe 就是把请求的资源当做 HTML渲染咯(即回调函数会作为文本显示)。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，也看到了 JSONP 的实现方式，可以看到 JSONP 的设计还是十分巧妙地，而实现上又非常简单。</p><p>当然了，现在也可以不使用 JSONP 的方式来处理跨域了，可以使用 <code>CORS</code> 来解决跨域。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;简单直白的解释 JSONP 的由来及实现原理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;JSONP-详解，不信你听不懂&quot;&gt;&lt;a href=&quot;#JSONP-详解，不信你听不懂&quot; class=&quot;headerlink&quot; title=&quot;JSONP</summary>
      
    
    
    
    <category term="前端" scheme="http://nickchenyx.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="JavaScript" scheme="http://nickchenyx.github.io/tags/JavaScript/"/>
    
    <category term="jsonp" scheme="http://nickchenyx.github.io/tags/jsonp/"/>
    
  </entry>
  
  <entry>
    <title>SPI 机制详解</title>
    <link href="http://nickchenyx.github.io/2018/04/17/spi-essentials-md/"/>
    <id>http://nickchenyx.github.io/2018/04/17/spi-essentials-md/</id>
    <published>2018-04-17T08:04:24.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>SPI, Service Provider Interface.</p></blockquote><blockquote><p>There are three essential components of a service provider framework:<br>a service interface, which providers implement;<br>a provider registration API, which the system uses to register implementations, giving clients access to them;<br>and a service access API, which clients use to obtain an instance of the service.</p></blockquote><blockquote><p>service provider framework 有三个重要的组件，</p></blockquote><blockquote><p>service interface， 提供实现<br>供应者的注册接口，可以用来注册接口实现，这样就可以访问到实现类。<br>获取 service 的api，可以用来获取 service 的实例。</p></blockquote><h2 id="SPI-的作用"><a href="#SPI-的作用" class="headerlink" title="SPI 的作用"></a>SPI 的作用</h2><p>SPI 主要是被框架的开发人员使用，比如 <code>java.sql.Driver</code> 接口，其他不同厂商可以针对同一接口做出不同的实现，mysql 和 postgresql 都有不同的实现提供给用户。Java 的 SPI 机制可以为某个接口注册服务实现。</p><p>Java 的 SPI 实现是由 <code>java.util.ServiceLoader</code> 类实现。当服务的提供者提供了一种接口的实现之后，需要在 classpath 下的 <code>META-INF/services/</code> 目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的 <code>META-INF/services/</code> 中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。</p><p>这是一个 service provider framework 大致结构</p><pre><code class="java">// Service provider framework sketch// Service 接口，我们要使用的功能在这里// Service interfacepublic interface Service &#123;    ... // Service-specific methods go here&#125;// Provider 用来获取 Service 实例// Service provider interfacepublic interface Provider &#123;    Service newService();&#125;// Noninstantiable class for service registration and accesspublic class Services &#123;    private Services() &#123; &#125;  // Prevents instantiation (Item 4)    // 用来维持 Provider 实例的 Map    // Maps service names to services    private static final Map&lt;String, Provider&gt; providers =        new ConcurrentHashMap&lt;String, Provider&gt;();    public static final String DEFAULT_PROVIDER_NAME = &quot;&lt;def&gt;&quot;;    // 注册 Provider 到 Map    // Provider registration API    public static void registerDefaultProvider(Provider p) &#123;        registerProvider(DEFAULT_PROVIDER_NAME, p);    &#125;    public static void registerProvider(String name, Provider p)&#123;        providers.put(name, p);    &#125;    // Service 获取接口    // Service access API    public static Service newInstance() &#123;        return newInstance(DEFAULT_PROVIDER_NAME);    &#125;    // 生成 Service 实例    public static Service newInstance(String name) &#123;        Provider p = providers.get(name);        if (p == null)            throw new IllegalArgumentException(                &quot;No provider registered with name: &quot; + name);        return p.newService();    &#125;&#125;</code></pre><p>上面的一段代码复现了上一节中提到的三个重要的组件。理解这段代码，对 SPI 机制原理的理解非常重要。</p><h2 id="基于-Interface-的-SPI-实现"><a href="#基于-Interface-的-SPI-实现" class="headerlink" title="基于 Interface 的 SPI 实现"></a>基于 Interface 的 SPI 实现</h2><p>至于为什么要基于 Interface 去做 SPI，那是因为读入的类你是不知道他的具体类的，也并不知道他有哪些方法，因为这是运行时加载的，编译期都没法获取。具体见下面伪代码：</p><pre><code class="java">// 如果不使用 interface// 比如现在要导入一个 Student 类class Student &#123;    public void say () &#123; println(&quot;hello, i&#39;m a student&quot;); &#125;&#125;// 平常使用main () &#123;    // 如果是 基于 SPI 运行时注册的类，你是不知道他的类名的，就像你并不知道他叫 Student    // 即使你知道他类名叫 Student，也没有用，因为这里的 Student 类需要 import 进来，而编译时并没有这个类，就没办法 import    Student stu = new Student();    stu.say();&#125;// 基于 SPIinterface Person &#123;    public void say();&#125;class Student implements Person &#123;    public void say () &#123; println(&quot;hello, i&#39;m a student&quot;); &#125;&#125;main () &#123;    // 动态加载类，使用 cast 就可以得到一个 Person接口的实例，就可以调用 say() 方法了    // 这里是直接获取 Service，可以看到能得到的 Service 是受限的，所以可以使用一个 Provider 并提供一个 API 来获取 Service，以期更完美的实现。（参看上面的三个重要组件。）    Person stu = (Person) Class.forName(&quot;com.xx.Student&quot;).newInstance();    stu.say();&#125;</code></pre><h2 id="JDK-中的-SPI-实现"><a href="#JDK-中的-SPI-实现" class="headerlink" title="JDK 中的 SPI 实现"></a>JDK 中的 SPI 实现</h2><p>JDK 的 SPI 实现是由 <code>java.util.ServiceLoader</code> 类实现。</p><p>以下是 <code>ServiceLoader</code> 类的成员变量：</p><pre><code class="java">public final class ServiceLoader&lt;S&gt;    implements Iterable&lt;S&gt;&#123;   // 可以看到默认的寻找配置的地址是 META-INF/services/    private static final String PREFIX = &quot;META-INF/services/&quot;;    // 使用 Class.forName 加载到配置文件中的对象，使用 service.cast(newInstance) 强转类型    // The class or interface representing the service being loaded    private Class&lt;S&gt; service;    // 类加载器，如果为null，默认使用 systemClassLoader    // The class loader used to locate, load, and instantiate providers    private ClassLoader loader;    // 存储 provider 的集合，存的是 service 的实例[service.cast(newInstance)]    // Cached providers, in instantiation order    private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();    // 迭代器，迭代过程中实例化 service并存到 map中    // The current lazy-lookup iterator    private LazyIterator lookupIterator;    ...&#125;</code></pre><p>其实原理也很简单，用目标对象 Interface 作为泛型，这样就能利用 Interface 的全限定名查找 <code>META-INF/services/</code> 下的文件，然后一行一行读取文件，加载 providers 到 map 中。所以 <code>ServiceLoader</code> 类是加载配置文件中全部的类的实例的，而且是一次性加载完成。</p><p>由上可知，整个类的其他部分就是在实现查找文件 =&gt; 获取类加载器 =&gt; 加载 class 对象 =&gt; cast 到指定 Interface 并存入 map，而整个过程都是在迭代器中完成的(<code>iterator.next()</code> 方法)。</p><p>哦，对了，重新加载直接调用 <code>reload()</code> 方法就好了，方法实现就是新建一个 <code>LazyIterator</code>，然后重复上面的动作。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;SPI, Service Provider Interface.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;There are three essential components of a service provide</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Java" scheme="http://nickchenyx.github.io/tags/Java/"/>
    
    <category term="SPI" scheme="http://nickchenyx.github.io/tags/SPI/"/>
    
  </entry>
  
  <entry>
    <title>Scala 学习总结</title>
    <link href="http://nickchenyx.github.io/2018/04/17/scala-for-the-impatient/"/>
    <id>http://nickchenyx.github.io/2018/04/17/scala-for-the-impatient/</id>
    <published>2018-04-17T08:04:08.000Z</published>
    <updated>2023-05-08T15:27:10.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这篇文章用来总结 Scala 学习中需要记录的知识，也会是以后 Scala 相关知识的索引。</p></blockquote><h3 id="Assignment"><a href="#Assignment" class="headerlink" title="Assignment"></a>Assignment</h3><p><code>Scala</code> 的赋值语句的返回值是 <code>Unit</code>， 因此不能使用 <code>x=y=1</code> 类似的赋值语法。<br>可以使用 `@`` 的小技巧来完成一个连续赋值的语法糖。</p><pre><code class="scala">y = 1 // Unit ()// not workx = y = 1// trickvar x@y = 1 // x = 1, y = 1</code></pre><h3 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h3><p>读取 Console 数据。</p><pre><code class="scala">import scala.io._val name = StdIn.readLine(&quot;your name:&quot;)print(&quot;your age:&quot;)val age = StdIn.readInt()</code></pre><h3 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h3><p>格式化输出，建议使用 <code>f</code>插值表达式，类型会在编译期得到检查。</p><pre><code class="scala">printf(&quot;%d year %f seconds&quot;, year, sec)// recommend, type-safeprint(f&quot;$year $&#123;sec&#125;%7.2f seconds&quot;)// raw textprint(raw&quot;\n 123&quot;)</code></pre><h3 id="Loops"><a href="#Loops" class="headerlink" title="Loops"></a>Loops</h3><p><code>Scala</code> 没有 <code>break</code>, <code>continue</code> 关键字，只能通过其他方式来实现。</p><pre><code class="scala">// 1. use Booleanvar flag = truefor (i &lt;- 1 to 9) &#123;    if (flag) &#123;        print(i)        flag = false    &#125; else flag = true&#125;// 2. use `return`def loop(): Int = &#123;  for (i &lt;- 1 to 10) &#123;    if (i == 2) return -1    else ()  &#125;  0&#125;// 3. use `break` method in the `Breaks` object// not recommend//   the control transfer is done by throwing and catching an exception,//   so you should avoid this mechanism when time is of essence.import scala.util.control.Breaks._def loop1(): Unit = &#123;  breakable &#123;    for (i &lt;- 1 to 10) &#123;      if (i == 3) break      else println(i)    &#125;  &#125;&#125;</code></pre><p><code>Scala</code> 的循环语句中，本地的变量名可以覆盖使用。</p><pre><code class="scala">val n = 10// local n will be overlappingfor (n &lt;- 1 to 9) &#123;    print(n) // print 1-9&#125;</code></pre><h3 id="Advanced-for-Loops"><a href="#Advanced-for-Loops" class="headerlink" title="Advanced for Loops"></a>Advanced for Loops</h3><p><code>Scala</code> 有更加便利的循环操作，可以完成多级循环以及列表推导。</p><p><strong>非常简单的语法糖完成多级的 for 循环</strong></p><pre><code class="scala">// multiple generatorsfor (i &lt;- 1 to 3; j &lt;- 1 to 3) println(f&quot;$&#123;i*10 + j&#125;%3d&quot;)// guardfor (i &lt;- 1 to 3; j &lt;- 1 to 3 if i!=j) println(f&quot;$&#123;i*10 + j&#125;%3d&quot;)// definitions, any number.for (i &lt;- 1 to 3; from = 4-i; j &lt;- from to 3) println(f&quot;$&#123;i*10 + j&#125;%3d&quot;)</code></pre><p><strong>列表推导</strong></p><p>列表推导生成的结果总是兼容第一个生成器的格式，可以看2、3例，第一个生成器是 String， 生成的就是 String格式。</p><pre><code class="scala">for (i &lt;- 1 to 9) yield i%5  // Yields Vector(1, 2, 3, 4, 0, 1, 2, 3, 4)// The generated collection is compatible with the first generator.for (c &lt;- &quot;Hello&quot;; i &lt;- 0 to 1) yield (c + i).toChar  // Yields &quot;HIeflmlmop&quot;for (i &lt;- 0 to 1; c &lt;- &quot;Hello&quot;) yield (c + i).toChar  // Yields Vector(&#39;H&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39;I&#39;, &#39;f&#39;, &#39;m&#39;, &#39;m&#39;, &#39;p&#39;)</code></pre><p>如果不想使用分号的风格 ，可以使用 {} 加换行 替代</p><pre><code class="scala">for &#123; i &lt;- 1 to 3  from = 4 - i  j &lt;- from to 3 &#125;</code></pre><h3 id="Variable-Arguments"><a href="#Variable-Arguments" class="headerlink" title="Variable Arguments"></a>Variable Arguments</h3><p>这是普通的可变长参数函数的实现，这里主要是指出一下 <code>Scala</code> 特有的语法。</p><p>能够使一个列表转变成可变参数的形式传递到方法内。</p><pre><code class="scala">def sum(args: Int *): Int = &#123;  if (args.isEmpty) 0  else args.head + sum(args.tail :_*)&#125;sum(1 to 5 :_*)</code></pre><h3 id="一道-String-Interpolator-的题目"><a href="#一道-String-Interpolator-的题目" class="headerlink" title="一道 String Interpolator 的题目"></a>一道 String Interpolator 的题目</h3><p>快捷的定义一个 java.time.LocalDate，使用到了 implicit 关键字。</p><pre><code class="scala">import java.time.LocalDateimplicit class DateInterpolator(val sc: StringContext) extends AnyVal &#123;  def date(args: Any*): LocalDate = &#123;    if (args.length != 3) throw new IllegalArgumentException(&quot;arguments should contain year, month, day.&quot;)    for (x &lt;- sc.parts) if (x.length &gt; 0 &amp;&amp; !x.equals(&quot;-&quot;)) throw new IllegalArgumentException(&quot;year-month-day format required&quot;)    LocalDate.of(args(0).toString.toInt, args(1).toString.toInt, args(2).toString.toInt)  &#125;&#125;val year = 2017val month = 1val day = 5date&quot;$year-$month-$day&quot; // java.time.LocalDate = 2017-01-05</code></pre><h3 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h3><p><code>Scala</code> 中的数组操作， <code>Array</code> 对应的是定长数组，<code>ArrayBuffer</code> 对应的是 Java的 <code>ArrayList</code>。</p><pre><code class="scala">// Traverse indicesfor (i &lt;- 0 until a.length) &#123; &#125;// orfor (i &lt;- a.indices) &#123; &#125;// To visit every second elementfor (i &lt;- 0 until a.length by 2) &#123; &#125;// To visit the elements starting from the end of the arrayfor (i &lt;- 0 until a.length by -1) &#123; &#125;// orfor (i &lt;- a.indices.reverse) &#123; &#125;// Traverse all values of the listfor (i &lt;- a) &#123; &#125;</code></pre><h3 id="Class"><a href="#Class" class="headerlink" title="Class"></a>Class</h3><p><code>Scala</code> 实现 class的方式不同于 Java。<code>Scala</code> 对所有的 <code>var</code>，<code>val</code>都会选择性地生成对应的 <code>Setter</code> &amp; <code>Getter</code>。</p><table><thead><tr><th>generate</th><th>var</th><th>val</th></tr></thead><tbody><tr><td>setter</td><td>√</td><td>×</td></tr><tr><td>getter</td><td>√</td><td>√</td></tr></tbody></table><p>如果声明是 <code>private</code> 的话，那么生成的 <code>Setter</code> &amp; <code>Getter</code> 也是 <code>private</code> 的。<br>如果不想要生成 <code>Setter</code> &amp; <code>Getter</code>，可以使用 <code>private[this]</code> 来修饰字段。<br>这里还有一个特殊点：字段声明是 <code>private</code> 的，只有该类的对象才能访问，这点和 Java的表现不同（Java 是只能在类部才能使用）。<br>下面代码中的 other也是一个 <code>Counter</code>类型，他也能访问 private var value。如果使用了 <code>private[this]</code>，表现就和 Java中一样了。</p><pre><code class="scala">class Counter &#123;  private var value = 0  def increment() &#123; value += 1 &#125;  def isLess(other : Counter) = value &lt; other.value    // Can access private ﬁeld of other object&#125;</code></pre><h3 id="Extractors-with-No-Arguments"><a href="#Extractors-with-No-Arguments" class="headerlink" title="Extractors with No Arguments"></a>Extractors with No Arguments</h3><p><code>Extractors</code> 可以用无参形式调用，这种情况下，它的返回值应该是一个 <code>Boolean</code>。<br>下面是一个样例，可以看到无参形式的 <code>Extractors</code>在模式匹配的时候使用。</p><pre><code class="scala">object Name &#123;  def unapply(input: String) = &#123;    val pos = input.indexOf(&quot; &quot;)    if (pos == -1) None    else Some((input.substring(0, pos), input.substring(pos + 1)))  &#125;&#125;object IsCompound &#123;  def unapply(input: String) = input.contains(&quot; &quot;)&#125;val author = &quot;king kong W&quot; // &quot;king kongW&quot;author match &#123;  case Name(first, IsCompound()) =&gt; print(first + &quot; mix &quot; )    // 当 IsCompound() 的返回值为 True时执行  case Name(first, last) =&gt; print(first + &quot; : &quot; + last)&#125;</code></pre><h3 id="Functions-as-Values"><a href="#Functions-as-Values" class="headerlink" title="Functions as Values"></a>Functions as Values</h3><p><code>Scala</code> 中函数(<code>Function</code>)也是第一等公民，可以作为值来传递。但是方法(<code>Method</code>)并不是函数，无法作为值传递。<br>下面展示一下方法如何转化为一个函数。<br><em>PS: 任何时候使用 def 关键词定义的都是方法，不是函数。</em></p><pre><code class="scala">import scala.math._// -- method from package object --val fun = ceil _    //  the _ turns the ceil method into a function.val func:(Double) =&gt; Double = ceil    // The _ suffix is not necessary when you use a method name in a context where    // a function is expected.// -- method from a class --val f = (_: String).charAt(_:Int)val fc: (String, Int) =&gt; Char = _.charAt(_)</code></pre><h3 id="Control-Abstractions"><a href="#Control-Abstractions" class="headerlink" title="Control Abstractions"></a>Control Abstractions</h3><p><code>Scala</code> 中有两种调用形式的参数， <code>call-by-name</code>和 <code>call-by-value</code>，大多数情况下只使用后者，现在有一种使用前者的情况。</p><pre><code class="scala">                // call-by-valuedef runInThread(block: () =&gt; Unit) &#123;  // 这是对一个参数的类型定义  new Thread &#123;    override def run() &#123; block() &#125; // 这里是调用函数  &#125;.start()&#125;runInThread &#123; () =&gt; println(&quot;Hi&quot;); Thread.sleep(10000); println(&quot;Bye&quot;) &#125;    // 这里调用的时候 必须是 `() =&gt;`带这个开头，就显得很多余</code></pre><pre><code class="scala">                // call-by-namedef runInThread(block: =&gt; Unit) &#123;  new Thread &#123;    override def run() &#123; block &#125;  &#125;.start()&#125;runInThread &#123; println(&quot;Hi&quot;); Thread.sleep(10000); println(&quot;Bye&quot;) &#125;    // 这里就可以省略掉 `() =&gt;`这个开头了，匿名函数写起来就很简洁</code></pre><p>可以看到 <code>call-by-name</code> 的参数调用使得方法在调用的时候非常方便，这里利用这一点实现类似 <code>while</code> 的语法。</p><pre><code class="scala">// definition          // call-by-name        // call-by-namedef until(condition: =&gt; Boolean)(block: =&gt; Unit) &#123;  if (!condition) &#123;    block    until(condition)(block)  &#125;&#125;// -- sample --var x = 10until (x == 0) &#123; // without `()=&gt;`, pretty concise  x -= 1  println(x)&#125;Unlike a regular (or call-by-value) parameter, the parameter expression is not evaluated when the function is called.After all, we don’t want x == 0 to evaluate to false in the call to until.</code></pre><p>这里说的非常重要，正是因为 <code>call-by-name</code> 的这个特性，才使得 <code>until</code> 方法可以对在运行时求值，而不是调用方法时 <code>x==0</code> 就已经作为值 <code>false</code> 传入了。</p><h3 id="Patterns-in-Variable-Declarations"><a href="#Patterns-in-Variable-Declarations" class="headerlink" title="Patterns in Variable Declarations"></a>Patterns in Variable Declarations</h3><p><code>Scala</code> 支持在变量声明时的解构操作，如下操作：</p><pre><code class="scala">val (x, y) = (1, 2)</code></pre><p>对于表达式 <code>val p(x1, ..., xn) = e</code>, 定义上等同与</p><pre><code class="scala">val $result = e match &#123; case p(x1, ..., xn) =&gt; (x1, ..., xn) &#125;val x1 = $result._1...val xn = $result._n</code></pre><p>其中 x1~xn 是 free variables，可以是任意的值，如下表达式，在 Scala中是合理的：</p><pre><code class="scala">val 2 = x</code></pre><p>等同于：</p><pre><code class="scala">var $result = x match &#123; case 2 =&gt; () &#125;// No assignments.</code></pre><p>并没有赋值语句。 这等同于：</p><pre><code class="scala">if (!(2 == x)) throw new MatchError</code></pre><h3 id="Partial-Functions"><a href="#Partial-Functions" class="headerlink" title="Partial Functions"></a>Partial Functions</h3><p><code>Scala</code> 又一迷之特性，这个语法糖不知道又会有多少玩法了。 偏函数，它的定义是这样的：</p><blockquote><p>a function which may not be defined for all inputs. PartialFunction[A, B]. (A is the parameter type, B the return type.)</p></blockquote><p>实际上如果一个偏函数穷举了所有可能性，那他就变成了一个 Function1。一个神奇的方法… Scala 设置了 Function1 到 Function22 总共可以允许 22 个参数。</p><p>然后就是神奇的语法糖了，甜不甜…</p><blockquote><p>A Seq[A] is a PartialFunction[Int, A], and a Map[K, V] is a PartialFunction[K, V].</p></blockquote><p>基于这个可以带来的操作：</p><pre><code class="scala">val names = Array(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Carmen&quot;)val scores = Map(&quot;Alice&quot; -&gt; 10, &quot;Carmen&quot; -&gt; 7)names.collect(scores) // Yields Array(10, 7)</code></pre><p>偏函数有 <code>lift</code> 函数，可以将偏函数转变为一个正常的函数，返回值是 <code>Option[T]</code>。反之也可以将一个有 <code>Option[T]</code> 返回值的函数，通过 <code>unlift</code> 转变为一个偏函数。</p><p>try 语句的 catch 子句就是一个偏函数，可以将这个字句赋值给一个变量。</p><pre><code class="scala">                // call by namedef tryCatch[T](b: =&gt; T, catcher: PartialFunction[Throwable, T]) =  try &#123; b &#125; catch catcherval result = tryCatch(str.toInt,  &#123; case _: NumberFormatException =&gt; -1 &#125;)</code></pre><p>可以看到 <code>catch</code> 子句就是一个偏函数， 通过 <code>catcher</code> 这个变量可以动态的切换偏函数。</p><p>不得不感叹一声，这个设计思维啊。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这篇文章用来总结 Scala 学习中需要记录的知识，也会是以后 Scala 相关知识的索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Assignment&quot;&gt;&lt;a href=&quot;#Assignment&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Scala" scheme="http://nickchenyx.github.io/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>实现Leader选举通过 Curator</title>
    <link href="http://nickchenyx.github.io/2018/04/17/CuratorFramework-leader/"/>
    <id>http://nickchenyx.github.io/2018/04/17/CuratorFramework-leader/</id>
    <published>2018-04-17T06:42:41.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Curator-Framework-深入了解"><a href="#Curator-Framework-深入了解" class="headerlink" title="Curator Framework 深入了解"></a>Curator Framework 深入了解</h1><p>本文受到 <a href="http://colobu.com">colobu</a> 前辈文章的指引，深入了解 Curator Framework 的工作流程，十分感谢 colobu 前辈的博文给予的启发和指导。</p><h2 id="选举功能实现-（Leader-Election）"><a href="#选举功能实现-（Leader-Election）" class="headerlink" title="选举功能实现 （Leader Election）"></a>选举功能实现 （Leader Election）</h2><p>Curator 提供了 Leader 选举的功能，用于在分布式计算中选举出一个节点作为一组节点的 Leader。Curator 提供了两种 Leader Election 的 Recipe：</p><h3 id="LeaderLatch"><a href="#LeaderLatch" class="headerlink" title="LeaderLatch"></a>LeaderLatch</h3><p>构造方法：</p><pre><code class="java">// LeaderLatch.classpublic LeaderLatch(CuratorFramework client, String latchPath)public LeaderLatch(CuratorFramework client, String latchPath, String id/*zk的 path：value 中的 value*/)</code></pre><p>同之前几章的使用风格，需要 <code>start()</code> 方法调用了才会开启选举。 <code>start()</code> 方法之后会调用真正的工作开始方法：</p><pre><code class="java">// LeaderLatch.classprivate synchronized void internalStart() &#123;        if ( state.get() == State.STARTED ) &#123; // 状态标记为开始 start()会完成            // 很重要的一条实践，客户端需要注册一个 lisenter 用来监听和 zk 连接的状态，比如中断、重连等            client.getConnectionStateListenable().addListener(listener);            //...            // 开始选举相关的工作            reset();            //...        &#125;&#125;</code></pre><p><code>reset()</code> 是一个会重复执行的方法，用来争抢当前的 leader：</p><pre><code class="java">// LeaderLatch.classvoid reset() throws Exception &#123;        setLeadership(false); // 当前不是leader，先置为 false；如果是leader不会进行这个操作        setNode(null); // 成为leader后会创建他的节点，存储起来方便下次删除旧节点        // Curator 方法非常通用的一种设计，专门用来做回调        BackgroundCallback callback = new BackgroundCallback() &#123;            @Override            public void processResult(CuratorFramework client, CuratorEvent event) throws Exception &#123;                // 不知道这个 debugResetWaitLatch 这个什么用... 一开始就被赋值 null，没有修改过。看起来开发开发另一个新特性的 hook。                // volatile CountDownLatch debugResetWaitLatch = null;                if ( debugResetWaitLatch != null ) &#123;                    debugResetWaitLatch.await();                    debugResetWaitLatch = null;                &#125;                // 节点创建成功                if ( event.getResultCode() == KeeperException.Code.OK.intValue() ) &#123;                    setNode(event.getName()); // 将当前 path 的名称记录下来，方便后续删除                    if ( state.get() == State.CLOSED ) &#123;                        setNode(null); // 这应该是一个安全检测，如果这时候leaderLatch被 close() 了，这里的 node 也就不存了。下面创建的也是临时节点。                    &#125; else &#123;                        getChildren(); // 获取latchPath（构造方法中传入的）下所有的节点，用来关键的判断谁拿到了 leader 权限                    &#125;                &#125; else &#123;                    log.error(&quot;getChildren() failed. rc = &quot; + event.getResultCode());                &#125;            &#125;        &#125;;        //这里可以看到创建的是一个临时节点，value的值就是 id    client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).inBackground(callback).forPath(ZKPaths.makePath(latchPath, LOCK_NAME), LeaderSelector.getIdBytes(id));    &#125;</code></pre><p><code>checkLeadership()</code> 是关键的终结方法了，他用来判断是谁拿到了 leader 权限：</p><pre><code class="java">// LeaderLatch.classprivate void getChildren() throws Exception &#123;        BackgroundCallback callback = new BackgroundCallback() &#123;            public void processResult(... )throws Exception &#123;                if ( event.getResultCode() == KeeperException.Code.OK.intValue() ) &#123;                    // 终结方法，找到对应的 leader                    checkLeadership(event.getChildren());                &#125;            &#125;        &#125;;    // 获取 latchPath 所有的节点client.getChildren().inBackground(callback).forPath(ZKPaths.makePath(latchPath, null));    &#125;</code></pre><p>篇幅有限，<code>checkLeadership()</code> 只介绍获得 leader 身份的情况了：</p><pre><code class="java">// LeaderLatch.classprivate void checkLeadership(List&lt;String&gt; children) throws Exception &#123;        final String localOurPath = ourPath.get(); // 当前 LeaderLacth 获取的节点        List&lt;String&gt; sortedChildren = LockInternals.getSortedChildren(LOCK_NAME, sorter, children); // 排序 latchPath 下所有的节点        int ourIndex = (localOurPath != null) ? sortedChildren.indexOf(ZKPaths.getNodeFromPath(localOurPath)) : -1; // 很明白的代码，查询当前 LeaderLacth 类的节点是否出现在排序数组中        if ( ourIndex &lt; 0 ) &#123;// 没有出现，就 reset() 方法重新来            log.error(&quot;Can&#39;t find our node. Resetting. Index: &quot; + ourIndex);            reset();        &#125;        else if ( ourIndex == 0 ) &#123;// 这里就是关键了， == 0，排在第一位，获得 leader 权限            setLeadership(true);        &#125; else &#123; /*...*/&#125;&#125;</code></pre><p>至此一个 Leader 选举的过程就完成了，Curator 利用了 ZooKeeper 的各种特性可谓是玩出了花儿…  </p><p>这里还介绍一个阻塞的方法等待当前对象获取到 Leader 身份：</p><pre><code class="java">// LeaderLatch.classpublic void await() throws InterruptedException, EOFException &#123;        synchronized(this) &#123; // 锁住当前对象            while ((state.get() == State.STARTED) &amp;&amp; !hasLeadership.get())&#123;                wait(); // 等待成为 Leader，这里 setLeadership(true) 的方法里会 notifyAll()来唤醒的            &#125;        &#125;        if ( state.get() != State.STARTED ) &#123;            throw new EOFException();        &#125;&#125;// 超时版本public boolean await(long timeout, TimeUnit unit) throws InterruptedException</code></pre><h3 id="LeaderSelector"><a href="#LeaderSelector" class="headerlink" title="LeaderSelector"></a>LeaderSelector</h3><p>Curator还提供了另外一种选举方法，注意涉及以下四个类：</p><ul><li>LeaderSelector</li><li>LeaderSelectorListener</li><li>LeaderSelectorListenerAdapter</li><li>CancelLeadershipException</li></ul><pre><code class="java">// LeaderSelector.class// 构造函数public LeaderSelector(CuratorFramework client, String leaderPath, LeaderSelectorListener listener)public LeaderSelector(CuratorFramework client, String leaderPath, ExecutorService executorService, LeaderSelectorListener listener)</code></pre><p>需要分析 <code>LeaderSelector</code> 依旧需要从 <code>start()</code> 方法开始，但在开始之前还有一个重要的方法 <code>autoRequeue()</code> 。如果需要该实例不停的去尝试获取 leader 身份，就需要调用此方法一次，在构造好该对象之后先调用 <code>autoRequeue()</code> 再 <code>start()</code>。</p><p><code>start()</code> 的逻辑是 ：</p><pre><code>start() -&gt; requeue() -&gt; internalRequeue() ----                               ↑             ↓ autoRequeue == true                               --------------</code></pre><p>在 <code>internalRequeue()</code> 中配置了一个 <code>Future</code> 任务执行 <code>doWorkLoop()</code> 方法，每次调用 <code>internalRequeue()</code> 是同步的，并且 <code>Future</code> 任务执行也是同步的，也就是必须一次一次同步的去尝试获取 leader 身份。</p><pre><code class="java">// LeaderSelector.classvoid doWork() throws Exception &#123;        hasLeadership = false;        try &#123;            // 这里就是关键了，这是一个分布式锁            // InterProcessMutex mutex            // 一旦这个拿到了就是持有锁了            // 下面只需要 takeLeadership 方法阻塞住方法，不让这边执行到 finally 代码块就好了            mutex.acquire();            hasLeadership = true;            try &#123;/*...*/&#125;            catch(/**/)&#123;/**/&#125;            finally &#123;                clearIsQueued();            &#125;        &#125;        catch ( InterruptedException e ) &#123;            Thread.currentThread().interrupt();            throw e;        &#125;        finally &#123;            if ( hasLeadership ) &#123;                hasLeadership = false;                try &#123;                    mutex.release(); // 释放了锁，其他的可以去竞争 leader 了                &#125;                catch ( Exception e )                &#123;                    ThreadUtils.checkInterrupted(e);                    log.error(&quot;The leader threw an exception&quot;, e);                    // ignore errors - this is just a safety                &#125;            &#125;        &#125;    &#125;</code></pre><p><strong>异常处理</strong><br><code>LeaderSelectorListener</code> 类继承了 <code>ConnectionStateListener</code> ，<code>LeaderSelector</code> 必须小心连接状态的改变。如果实例成为 leader,  当 <code>SUSPENDED</code> 状态出现时， 实例必须假定在重新连接成功之前它可能不再是 leader了。 如果 <code>LOST</code> 状态出现， 实例不再是 leader， <code>takeLeadership()</code> 方法返回。</p><p><em>重要：</em>推荐处理方式是当收到 <code>SUSPENDED</code> 或 <code>LOST</code> 时抛出 <code>CancelLeadershipException</code> 异常。 这会导致 <code>LeaderSelector</code> 实例中断并取消执行 <code>takeLeadership()</code>方法的异常。Curator 提供了 <code>LeaderSelectorListenerAdapter</code> 以供继承，此 <code>Adapter</code> 提供了推荐的处理逻辑。</p><pre><code class="java">public abstract class LeaderSelectorListenerAdapter implements LeaderSelectorListener &#123;    @Override    public void stateChanged(CuratorFramework client, ConnectionState newState )&#123;        if ( client.getConnectionStateErrorPolicy().isErrorState(newState) )&#123;            throw new CancelLeadershipException();        &#125;    &#125;&#125;</code></pre><p>这里跑出异常以中断  <code>takeLeadership()</code>方法只能抛出<code>CancelLeadershipException</code> 异常：</p><pre><code class="java">// LeaderSelector.WrappedListener.classpublic void stateChanged(CuratorFramework client, ConnectionState newState) &#123;       try&#123;                listener.stateChanged(client, newState);       &#125; catch ( CancelLeadershipException dummy ) &#123;                // 中断逻辑                 leaderSelector.interruptLeadership();       &#125;&#125;</code></pre><p>与 <code>LeaderLatch</code> 相比， 通过 <code>LeaderSelectorListener</code> 可以对领导权进行控制， 在适当的时候释放领导权，这样每个节点都有可能获得领导权。 </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Curator-Framework-深入了解&quot;&gt;&lt;a href=&quot;#Curator-Framework-深入了解&quot; class=&quot;headerlink&quot; title=&quot;Curator Framework 深入了解&quot;&gt;&lt;/a&gt;Curator Framework 深入</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Curator" scheme="http://nickchenyx.github.io/tags/Curator/"/>
    
    <category term="ZooKeeper" scheme="http://nickchenyx.github.io/tags/ZooKeeper/"/>
    
    <category term="Leader Election" scheme="http://nickchenyx.github.io/tags/Leader-Election/"/>
    
    <category term="选举" scheme="http://nickchenyx.github.io/tags/%E9%80%89%E4%B8%BE/"/>
    
  </entry>
  
  <entry>
    <title>使用ZK实现 Cache 通过 Curator</title>
    <link href="http://nickchenyx.github.io/2018/04/14/CuratorFramework-Cache/"/>
    <id>http://nickchenyx.github.io/2018/04/14/CuratorFramework-Cache/</id>
    <published>2018-04-14T09:03:31.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Curator-Framework-深入了解"><a href="#Curator-Framework-深入了解" class="headerlink" title="Curator Framework 深入了解"></a>Curator Framework 深入了解</h1><p>本文受到 <a href="http://colobu.com">colobu</a> 前辈文章的指引，深入了解 Curator Framework 的工作流程，十分感谢 colobu 前辈的博文给予的启发和指导。</p><h2 id="ZooKeeper-Cache-实现"><a href="#ZooKeeper-Cache-实现" class="headerlink" title="ZooKeeper Cache 实现"></a>ZooKeeper Cache 实现</h2><p>利用 ZooKeeper 在集群的节点上缓存数据。<a href="https://github.com/apache/curator/blob/master/curator-examples/src/main/java/cache">示例代码</a></p><h3 id="Path-Cache"><a href="#Path-Cache" class="headerlink" title="Path Cache"></a>Path Cache</h3><p>Path Cache 使用 ZK 的节点作为 KV 存储系统，在实现上涉及的类：</p><ul><li><code>PathChildrenCache</code></li><li><code>PathChildrenCacheEvent</code></li><li><code>PathChildrenCacheListener</code></li><li><code>ChildData</code></li></ul><p><code>PathChildrenCache</code> 是主要类，他的构造方法是</p><pre><code class="java"> public PathChildrenCache(CuratorFramework client,                              String path,                             boolean cacheData /*是否缓存node，会缓存在一个 ConcurrentHashMap内*/)</code></pre><p>比较奇特的是，设计上<code>PathChildrenCache</code> 只负责获取数据，也就是只有 <code>list</code>、<code>get</code> 的操作，并没有 <code>set</code>、 <code>remove</code> 操作，需要新增数据之类的都是统一通过 <code>CuratorFramework</code> 构造出的 client 去做对应操作（任何对 zk 节点完成增删的操作都可）。<code>PathChildrenCache</code> 通过对构造函数中填入的 PATH 路径进行监听，这里有两个 Watcher，<code>childrenWatcher</code> 负责监听节点的增加，<code>dataWatcher</code>负责监听节点数据的改动和节点的删除。<br>构造好一个 <code>PathChildrenCache</code> 后需要 <code>start()</code>  后才能正常使用，调用 close()来结束使用。<code>start()</code> 方法中也可以传入 <code>StartMode</code>，用来为初始的 cache 设置暖场方式(warm)：</p><ol><li><code>NORMAL</code>: 初始时为空。</li><li><code>BUILD_INITIAL_CACHE</code>: 在这个方法返回之前调用<code>rebuild()</code>，此方法会将 ZK 的节点 kv 存到本地缓存（<code>ConcurrentHashMap</code>）内。</li><li><code>POST_INITIALIZED_EVENT</code>: 当Cache初始化数据后发送一个<code>PathChildrenCacheEvent.Type#INITIALIZED</code> 事件</li></ol><p>获取当前的 Cache 值可以使用如下方法：</p><pre><code class="java">// PathChildrenCache.class// 获取所有的缓存数据public List&lt;ChildData&gt; getCurrentData() &#123;        return ImmutableList.copyOf(Sets.&lt;ChildData&gt;newTreeSet(currentData/*这就是本地缓存 concurrentHashMap*/.values()));&#125;// 获取指定 PATH 下的缓存数据（实际就是用 key）public ChildData getCurrentData(String fullPath) &#123;        return currentData/*这就是本地缓存 concurrentHashMap*/.get(fullPath);&#125;</code></pre><p>可以增加 listener 监听缓存变化：</p><pre><code class="java">/*这里的 Listener 就是 PathChildrenCacheListener 的实例，据此新建自己的监听器。*/cache/*PathChildrenCache 的实例*/.getListenable().addListener(listener);</code></pre><h3 id="Node-Cache"><a href="#Node-Cache" class="headerlink" title="Node Cache"></a>Node Cache</h3><p>Node Cache 顾名思义就是只对一个 Node 节点做监控，涉及到下面的三个类：</p><ul><li>NodeCache</li><li>NodeCacheListener</li><li>ChildData</li></ul><p>Node Cache 在更新数据的时候并不是同步的，也就意味着并发修改数据返回意料之外的结果。使用这个缓存的时候需要自己多加注意。具体的使用方法同 Path Cache，只是 Node Cache 的 <code>getCurrentData()</code> 只会返回一个 ChildData 了。</p><h3 id="Tree-Node"><a href="#Tree-Node" class="headerlink" title="Tree Node"></a>Tree Node</h3><p>Tree Node 既可以监控节点的状态，也监控节点的子节点的状态。涉及到下面四个类：</p><ul><li>TreeCache</li><li>TreeCacheListener</li><li>TreeCacheEvent</li><li>ChildData</li></ul><p>TreeCache 使用 Builder 模式来构造：</p><pre><code class="java">// TreeCache.Builder.classprivate Builder(CuratorFramework client, String path)&#123;    this.client = checkNotNull(client);    this.path = validatePath(path);&#125;// 构造出来一个 builder 后可以配置private boolean cacheData = true;private boolean dataIsCompressed = false;private ExecutorService executorService = null;private int maxDepth = Integer.MAX_VALUE;private boolean createParentNodes = false;</code></pre><p>TreeCache 也可以使用 <code>getCurrentChildren(String path)</code> 方法获取 path 下一级的所有的 kv 对。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Curator-Framework-深入了解&quot;&gt;&lt;a href=&quot;#Curator-Framework-深入了解&quot; class=&quot;headerlink&quot; title=&quot;Curator Framework 深入了解&quot;&gt;&lt;/a&gt;Curator Framework 深入</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Curator" scheme="http://nickchenyx.github.io/tags/Curator/"/>
    
    <category term="Cache" scheme="http://nickchenyx.github.io/tags/Cache/"/>
    
    <category term="缓存" scheme="http://nickchenyx.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
    <category term="ZooKeeper" scheme="http://nickchenyx.github.io/tags/ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>实现分布式队列通过 Curator</title>
    <link href="http://nickchenyx.github.io/2018/04/12/CuratorFramework-DistributedQueue/"/>
    <id>http://nickchenyx.github.io/2018/04/12/CuratorFramework-DistributedQueue/</id>
    <published>2018-04-12T03:33:29.000Z</published>
    <updated>2023-05-08T15:27:10.762Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Curator-Framework-深入了解"><a href="#Curator-Framework-深入了解" class="headerlink" title="Curator Framework 深入了解"></a>Curator Framework 深入了解</h1><p>本文受到 <a href="http://colobu.com">colobu</a> 前辈文章的指引，深入了解 Curator Framework 的工作流程，十分感谢 colobu 前辈的博文给予的启发和指导。</p><h2 id="分布式队列实现（DistributedQueue-实现）"><a href="#分布式队列实现（DistributedQueue-实现）" class="headerlink" title="分布式队列实现（DistributedQueue 实现）"></a>分布式队列实现（DistributedQueue 实现）</h2><p><code>DistributedQueue</code> 是最普通的一种队列。 它设计以下四个类：</p><ul><li><code>QueueBuilder</code></li><li><code>QueueConsumer</code></li><li><code>QueueSerializer</code></li><li><code>DistributedQueue</code></li></ul><p>创建队列使用 <code>QueueBuilder</code>,它也是其它队列的创建类，看看他的 builder 方法：</p><pre><code class="java">    public static &lt;T&gt; QueueBuilder&lt;T&gt; builder(CuratorFramework client, QueueConsumer&lt;T&gt; consumer, QueueSerializer&lt;T&gt; serializer, String queuePath) &#123;            return new QueueBuilder(client, consumer, serializer, queuePath);        &#125;</code></pre><p>这里有四个入参，分别对应着客户端连接对象，consumer 对象，serializer 对象，path 节点对象。队列的消费就是通过 consumer 对象来实现的；serializer 对象负责存入 queue 的数据序列化和消费时的反序列化。</p><pre><code class="java">    // 创建了一个没有 consumer 的 builder    QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, null, createQueueSerializer(), PATH);     // 创建了一个 queue 对象    DistributedQueue&lt;String&gt; queue = builder.buildQueue();    // 启动 queue    queue.start();    // 这样操作就可以往 queue 里塞入消息了    queue.put(&quot;Test Message.&quot;);</code></pre><p>注意此时的 queue 是没有消费者的，如果需要消费者可以新建一个 queue_2 对象来消费对应 queuePath 的消息队列。当然也可以在创建 queue 对象的时候配置好 consumer 就可以即刻消费了。</p><pre><code class="java">    // 注意这里的第二个入参，配置了 consumer，此时的 queue_2 如果 start 会直接开始消费队列中的消息    DistributedQueue&lt;String&gt; queue_2 = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH).buildQueue();</code></pre><p>具体的逻辑可以看 queue.start() 时做了什么操作：</p><pre><code class="java">    // DistributedQueue.class    private final boolean isProducerOnly;    ...    // 构造函数中做了如下判断    this.isProducerOnly = consumer == null;    // 下面就是配置了 consumer 时会进行的操作，通过 runLoop 方法去不停的消费队列    // public void start() throws Exception    if (!this.isProducerOnly) &#123;        this.service.submit(new Callable&lt;Object&gt;() &#123;             public Object call() &#123;                 DistributedQueue.this.runLoop();                 return null;             &#125;        &#125;);    &#125;    // private DistributedQueue.ProcessMessageBytesCode processMessageBytes(String itemNode, byte[] bytes) throws Exception     // 伪代码 可以看到这个 processMessageBytes 方法是真正消费的地方，先把消息反序列化之后再使用 consumer 对象的 consumeMessage() 方法    this.consumer.consumeMessage(ItemSerializer.deserialize(bytes, this.serializer));</code></pre><p>上面的代码中还有个缺点，通过源码可知，消费队列是先将消息从队列中移除，再由 consumer 消费。 这两个步骤不是原子的，QueueBuilder 提供了 lockPath(String path) 方法以保证消费安全。当消费者消费数据时持有锁，这样其它消费者不能消费此消息。如果消费失败或者进程死掉，消息可以交给其它进程。这会带来一点性能的损失。 最好还是单消费者模式使用队列。</p><pre><code class="java">    // DistributedQueue.class    // private void processChildren(List&lt;String&gt; children, long currentVersion) throws Exception    // 这里就可以看到加锁和不加锁采用的是不同的策略    if (isUsingLockSafety) &#123;        DistributedQueue.this.processWithLockSafety(itemNode, DistributedQueue.ProcessType.NORMAL);    &#125; else &#123;        DistributedQueue.this.processNormally(itemNode, DistributedQueue.ProcessType.NORMAL);    &#125;</code></pre><h3 id="分布式含ID队列实现（DistributedIdQueue-实现）"><a href="#分布式含ID队列实现（DistributedIdQueue-实现）" class="headerlink" title="分布式含ID队列实现（DistributedIdQueue 实现）"></a>分布式含ID队列实现（DistributedIdQueue 实现）</h3><p><code>DistributedIdQueue</code> 和上面的队列类似， 但是可以为队列中的每一个元素设置一个ID。 可以通过ID把队列中任意的元素移除。 </p><p>通过下面方法创建：</p><pre><code>builder.buildIdQueue()</code></pre><p>放入元素时：</p><pre><code>queue.put(aMessage, messageId);</code></pre><p>移除元素时：</p><pre><code>int numberRemoved = queue.remove(messageId);</code></pre><p>看下他是如何实现 id 这个属性的：</p><pre><code class="java">    // DistributedIdQueue.class    private String makeIdPath(String itemId) &#123;       return this.queue.makeItemPath() + &#39;|&#39; + fixId(itemId) + &#39;|&#39;;    &#125;    // DistributedQueue.class    String makeItemPath() &#123;       return ZKPaths.makePath(this.queuePath, &quot;queue-&quot;);    &#125;</code></pre><p>可以看到他是直接通过 id 的值加入 path 生成了一个指定的节点存储数据，这样也可以逆向操作得到该节点的 path 从而删除元素。</p><p>添加元素调用的都是 DistributedQueue 中的 internalPut() 方法：</p><pre><code class="java">    boolean internalPut(T item, MultiItem&lt;T&gt; multiItem, String path, int maxWait, TimeUnit unit) throws Exception</code></pre><p>DistributedIdQueue 和 DistributedQueue 添加元素的 put 方法实际上都是调用到这个方法。DistributedIdQueue 是自己构建了 path，而 DistributedQueue 是自动生成如下的节点 path。</p><pre><code>queue-0000000009queue-0000000008queue-0000000007queue-0000000006queue-0000000005queue-0000000004queue-0000000003queue-0000000002</code></pre><h3 id="分布式优先级队列实现（DistributedPriorityQueue-实现）"><a href="#分布式优先级队列实现（DistributedPriorityQueue-实现）" class="headerlink" title="分布式优先级队列实现（DistributedPriorityQueue 实现）"></a>分布式优先级队列实现（DistributedPriorityQueue 实现）</h3><p>优先级队列对队列中的消息按照优先级进行排序。 Priority 越小越靠前， 优先被消费。</p><p>创建一个 <code>DistributedPriorityQueue</code> 的方式如下：</p><pre><code class="java">    DistributedPriorityQueue&lt;String&gt; queue = builder.buildPriorityQueue(0/*minItemsBeforeRefresh*/);</code></pre><p>可以看到只需要配置一个 <code>minItemsBeforeRefresh</code> 参数，这个参数用来对比当前是否需要进行重排序；需要强制重排序还需要配合 <code>refreshOnWatch</code> 参数，不过在 builder 创建 <code>DistributedPriorityQueue</code> 的时候就在 <code>DistributedQueue</code> 的构造参数上设置该值为 <code>true</code> 了。</p><pre><code class="java">    // DistributedPriorityQueue 的构造参数    DistributedPriorityQueue(.../*很多入参*/) &#123;            Preconditions.checkArgument(minItemsBeforeRefresh &gt;= 0, &quot;minItemsBeforeRefresh cannot be negative&quot;);            this.queue = new DistributedQueue(client, consumer, serializer, queuePath, threadFactory, executor, minItemsBeforeRefresh, true/*refreshOnWatch 直接设置为 true 了。*/, lockPath, maxItems, putInBackground, finalFlushMs);        &#125;</code></pre><p>强制重排序的逻辑如下：</p><pre><code class="java">    // DistributedQueue.class    //private void processChildren(List&lt;String&gt; children, long currentVersion) throws Exception     int min = this.minItemsBeforeRefresh;    ...    while(..)&#123;        // min 就是强制刷新所需的最小的元素数量，或称之你的程序可以容忍的不排序的最小值。        // 从源码可以看出 minItemsBeforeRefresh 被设置为 1 或者 0 都是可以直接触发重排序的一个决定因素        if (min-- &lt;= 0 &amp;&amp; this.refreshOnWatch &amp;&amp; currentVersion != this.childrenCache.getData().version) &#123;            // 这里的 processedLatch 是一个 Semaphore 对象             // final Semaphore processedLatch = new Semaphore(0);            // 可以看到代码段的最下方的 acquire 代码，线程池消费完所有的代码之后才会 release 所有的信号量            // 这里直接释放了，这样处理逻辑的代码可以直接退出            // 然后在 runLoop 下一次循环的时候会进行 collection 的 sort            processedLatch.release(children.size());            break;        &#125;        ...        消费消息的代码        ...    &#125;    processedLatch.acquire(children.size());  </code></pre><h3 id="分布式Delay队列实现（DistributedDelayQueue-实现）"><a href="#分布式Delay队列实现（DistributedDelayQueue-实现）" class="headerlink" title="分布式Delay队列实现（DistributedDelayQueue 实现）"></a>分布式Delay队列实现（DistributedDelayQueue 实现）</h3><p><code>DistributedDelayQueue</code> 中新增的元素有个delay值， 消费者隔一段时间才能收到元素。同样的可以通过 QueueBuilder 来创建该对象：</p><pre><code class="java">    DistributedDelayQueue&lt;MessageType&gt; queue = builder.buildDelayQueue();</code></pre><p>放入元素时可以指定 <code>delayUntilEpoch</code>：</p><pre><code>queue.put(aMessage, delayUntilEpoch);</code></pre><p>注意 <code>delayUntilEpoch</code> 不是离现在的一个时间间隔， 比如20毫秒，而是未来的一个时间戳，如 <code>System.currentTimeMillis() + 10</code> 秒。 如果delayUntilEpoch的时间已经过去，消息会立刻被消费者接收。</p><p>延时队列的实现同样基于 <code>DistributedQueue</code>，在 <code>runLoop</code> 方法的逻辑中，会获取元素的 delay 值，默认直接返回 0，<code>DistributedDelayQueue</code> 重写了获取 delay 时间的方法：</p><pre><code class="java">    // DistributedQueue.class    // private void runLoop()     maxWaitMs = this.getDelay((String)children.get(0));    if (maxWaitMs &lt;= 0L) &#123;        this.processChildren(children, currentVersion);    &#125;</code></pre><pre><code class="java">    // DistributedDelayQueue.class    // 构造函数    DistributedDelayQueue(.../*很多入参*/) &#123;            Preconditions.checkArgument(minItemsBeforeRefresh &gt;= 0, &quot;minItemsBeforeRefresh cannot be negative&quot;);            this.queue = new DistributedQueue&lt;T&gt;(.../*很多入参*/) &#123;                // override 了原有的方法，DistributedQueue 中的 getDelay 方法直接返回 0L                protected long getDelay(String itemNode) &#123;                    return this.getDelay(itemNode, System.currentTimeMillis());                &#125;                private long getDelay(String itemNode, long sortTime) &#123;                    long epoch = DistributedDelayQueue.getEpoch(itemNode);                    return epoch - sortTime;                &#125;                // 重写了排序的方法，根据 delay 的时间来排序了                protected void sortChildren(List&lt;String&gt; children) &#123;                    final long sortTime = System.currentTimeMillis();                    Collections.sort(children, new Comparator&lt;String&gt;() &#123;                        public int compare(String o1, String o2) &#123;                            long diff = getDelay(o1, sortTime) - getDelay(o2, sortTime);                            return diff &lt; 0L ? -1 : (diff &gt; 0L ? 1 : 0);                        &#125;                    &#125;);                &#125;            &#125;;        &#125;</code></pre><h3 id="JDK-Queue风格接口的分布式队列实现（SimpleDistributedQueue-实现）"><a href="#JDK-Queue风格接口的分布式队列实现（SimpleDistributedQueue-实现）" class="headerlink" title="JDK Queue风格接口的分布式队列实现（SimpleDistributedQueue 实现）"></a>JDK Queue风格接口的分布式队列实现（SimpleDistributedQueue 实现）</h3><p>前面虽然实现了各种队列，但并没有 JDK 中的队列接口风格实现。 <code>SimpleDistributedQueue</code> 提供了和JDK一致性的接口(但是没有实现Queue接口)。 创建很简单：</p><pre><code>public SimpleDistributedQueue(CuratorFramework client, String path)</code></pre><p>增加元素：</p><pre><code class="java">    public boolean offer(byte[] data) throws Exception    // 即往一个既定的 path 下有以 qn- 开头的子路径，如 /path/qn-0000001 </code></pre><p>删除元素：</p><pre><code class="java">    public byte[] take() throws Exception    // 获取队列最前的元素，同时zk剔除该路径    // 使用 CountDownLatch 来达到超时的设置，虽然 take 是没有设置超时的... 也就是要一致等待 zk 回应</code></pre><p>另外还提供了其它方法：</p><pre><code class="java">    // 获取元素 同 element() 返回队列最前的元素    public byte[] peek() throws Exception    // 和 take() 实际上是一样的方法，但是这里会有超时配置，见上关于 take()的解释    public byte[] poll(long timeout, TimeUnit unit) throws Exception    // 和 remove() 操作一样    public byte[] poll() throws Exception    // 直接删掉队列最前的元素    public byte[] remove() throws Exception    public byte[] element() throws Exception</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Curator-Framework-深入了解&quot;&gt;&lt;a href=&quot;#Curator-Framework-深入了解&quot; class=&quot;headerlink&quot; title=&quot;Curator Framework 深入了解&quot;&gt;&lt;/a&gt;Curator Framework 深入</summary>
      
    
    
    
    <category term="后端" scheme="http://nickchenyx.github.io/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Curator" scheme="http://nickchenyx.github.io/tags/Curator/"/>
    
    <category term="ZooKeeper" scheme="http://nickchenyx.github.io/tags/ZooKeeper/"/>
    
    <category term="Distributed" scheme="http://nickchenyx.github.io/tags/Distributed/"/>
    
    <category term="分布式" scheme="http://nickchenyx.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
</feed>
